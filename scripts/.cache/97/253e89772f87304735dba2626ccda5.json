{"id":"node_modules/@tensorflow/tfjs-layers/dist/initializers.js","dependencies":[{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js.map","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\src\\initializers.ts","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\package.json","includedInParent":true,"mtime":1582861032163},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1581030261368},{"name":"@tensorflow/tfjs-core","loc":{"line":25,"column":26},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.esm.js"},{"name":"./backend/tfjs_backend","loc":{"line":26,"column":16},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\backend\\tfjs_backend.js"},{"name":"./common","loc":{"line":27,"column":23},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\common.js"},{"name":"./errors","loc":{"line":28,"column":23},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\errors.js"},{"name":"./keras_format/initializer_config","loc":{"line":29,"column":35},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\keras_format\\initializer_config.js"},{"name":"./utils/generic_utils","loc":{"line":30,"column":30},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\generic_utils.js"},{"name":"./utils/math_utils","loc":{"line":31,"column":27},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\math_utils.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar K = require(\"./backend/tfjs_backend\");\nvar common_1 = require(\"./common\");\nvar errors_1 = require(\"./errors\");\nvar initializer_config_1 = require(\"./keras_format/initializer_config\");\nvar generic_utils_1 = require(\"./utils/generic_utils\");\nvar math_utils_1 = require(\"./utils/math_utils\");\nfunction checkFanMode(value) {\n    generic_utils_1.checkStringTypeUnionValue(initializer_config_1.VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\nexports.checkFanMode = checkFanMode;\nfunction checkDistribution(value) {\n    generic_utils_1.checkStringTypeUnionValue(initializer_config_1.VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\nexports.checkDistribution = checkDistribution;\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nvar Initializer = /** @class */ (function (_super) {\n    __extends(Initializer, _super);\n    function Initializer() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    Initializer.prototype.fromConfigUsesCustomObjects = function () {\n        return false;\n    };\n    Initializer.prototype.getConfig = function () {\n        return {};\n    };\n    return Initializer;\n}(tfjs_core_1.serialization.Serializable));\nexports.Initializer = Initializer;\nvar Zeros = /** @class */ (function (_super) {\n    __extends(Zeros, _super);\n    function Zeros() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    Zeros.prototype.apply = function (shape, dtype) {\n        return tfjs_core_1.zeros(shape, dtype);\n    };\n    /** @nocollapse */\n    Zeros.className = 'Zeros';\n    return Zeros;\n}(Initializer));\nexports.Zeros = Zeros;\ntfjs_core_1.serialization.registerClass(Zeros);\nvar Ones = /** @class */ (function (_super) {\n    __extends(Ones, _super);\n    function Ones() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    Ones.prototype.apply = function (shape, dtype) {\n        return tfjs_core_1.ones(shape, dtype);\n    };\n    /** @nocollapse */\n    Ones.className = 'Ones';\n    return Ones;\n}(Initializer));\nexports.Ones = Ones;\ntfjs_core_1.serialization.registerClass(Ones);\nvar Constant = /** @class */ (function (_super) {\n    __extends(Constant, _super);\n    function Constant(args) {\n        var _this = _super.call(this) || this;\n        if (typeof args !== 'object') {\n            throw new errors_1.ValueError(\"Expected argument of type ConstantConfig but got \" + args);\n        }\n        if (args.value === undefined) {\n            throw new errors_1.ValueError(\"config must have value set but got \" + args);\n        }\n        _this.value = args.value;\n        return _this;\n    }\n    Constant.prototype.apply = function (shape, dtype) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () { return tfjs_core_1.mul(tfjs_core_1.scalar(_this.value), tfjs_core_1.ones(shape, dtype)); });\n    };\n    Constant.prototype.getConfig = function () {\n        return {\n            value: this.value,\n        };\n    };\n    /** @nocollapse */\n    Constant.className = 'Constant';\n    return Constant;\n}(Initializer));\nexports.Constant = Constant;\ntfjs_core_1.serialization.registerClass(Constant);\nvar RandomUniform = /** @class */ (function (_super) {\n    __extends(RandomUniform, _super);\n    function RandomUniform(args) {\n        var _this = _super.call(this) || this;\n        _this.DEFAULT_MINVAL = -0.05;\n        _this.DEFAULT_MAXVAL = 0.05;\n        _this.minval = args.minval || _this.DEFAULT_MINVAL;\n        _this.maxval = args.maxval || _this.DEFAULT_MAXVAL;\n        _this.seed = args.seed;\n        return _this;\n    }\n    RandomUniform.prototype.apply = function (shape, dtype) {\n        return tfjs_core_1.randomUniform(shape, this.minval, this.maxval, dtype);\n    };\n    RandomUniform.prototype.getConfig = function () {\n        return { minval: this.minval, maxval: this.maxval, seed: this.seed };\n    };\n    /** @nocollapse */\n    RandomUniform.className = 'RandomUniform';\n    return RandomUniform;\n}(Initializer));\nexports.RandomUniform = RandomUniform;\ntfjs_core_1.serialization.registerClass(RandomUniform);\nvar RandomNormal = /** @class */ (function (_super) {\n    __extends(RandomNormal, _super);\n    function RandomNormal(args) {\n        var _this = _super.call(this) || this;\n        _this.DEFAULT_MEAN = 0.;\n        _this.DEFAULT_STDDEV = 0.05;\n        _this.mean = args.mean || _this.DEFAULT_MEAN;\n        _this.stddev = args.stddev || _this.DEFAULT_STDDEV;\n        _this.seed = args.seed;\n        return _this;\n    }\n    RandomNormal.prototype.apply = function (shape, dtype) {\n        dtype = dtype || 'float32';\n        if (dtype !== 'float32' && dtype !== 'int32') {\n            throw new errors_1.NotImplementedError(\"randomNormal does not support dType \" + dtype + \".\");\n        }\n        return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n    };\n    RandomNormal.prototype.getConfig = function () {\n        return { mean: this.mean, stddev: this.stddev, seed: this.seed };\n    };\n    /** @nocollapse */\n    RandomNormal.className = 'RandomNormal';\n    return RandomNormal;\n}(Initializer));\nexports.RandomNormal = RandomNormal;\ntfjs_core_1.serialization.registerClass(RandomNormal);\nvar TruncatedNormal = /** @class */ (function (_super) {\n    __extends(TruncatedNormal, _super);\n    function TruncatedNormal(args) {\n        var _this = _super.call(this) || this;\n        _this.DEFAULT_MEAN = 0.;\n        _this.DEFAULT_STDDEV = 0.05;\n        _this.mean = args.mean || _this.DEFAULT_MEAN;\n        _this.stddev = args.stddev || _this.DEFAULT_STDDEV;\n        _this.seed = args.seed;\n        return _this;\n    }\n    TruncatedNormal.prototype.apply = function (shape, dtype) {\n        dtype = dtype || 'float32';\n        if (dtype !== 'float32' && dtype !== 'int32') {\n            throw new errors_1.NotImplementedError(\"truncatedNormal does not support dType \" + dtype + \".\");\n        }\n        return tfjs_core_1.truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n    };\n    TruncatedNormal.prototype.getConfig = function () {\n        return { mean: this.mean, stddev: this.stddev, seed: this.seed };\n    };\n    /** @nocollapse */\n    TruncatedNormal.className = 'TruncatedNormal';\n    return TruncatedNormal;\n}(Initializer));\nexports.TruncatedNormal = TruncatedNormal;\ntfjs_core_1.serialization.registerClass(TruncatedNormal);\nvar Identity = /** @class */ (function (_super) {\n    __extends(Identity, _super);\n    function Identity(args) {\n        var _this = _super.call(this) || this;\n        _this.gain = args.gain != null ? args.gain : 1.0;\n        return _this;\n    }\n    Identity.prototype.apply = function (shape, dtype) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            if (shape.length !== 2 || shape[0] !== shape[1]) {\n                throw new errors_1.ValueError('Identity matrix initializer can only be used for' +\n                    ' 2D square matrices.');\n            }\n            else {\n                return tfjs_core_1.mul(_this.gain, tfjs_core_1.eye(shape[0]));\n            }\n        });\n    };\n    Identity.prototype.getConfig = function () {\n        return { gain: this.gain };\n    };\n    /** @nocollapse */\n    Identity.className = 'Identity';\n    return Identity;\n}(Initializer));\nexports.Identity = Identity;\ntfjs_core_1.serialization.registerClass(Identity);\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(shape, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var fanIn;\n    var fanOut;\n    common_1.checkDataFormat(dataFormat);\n    if (shape.length === 2) {\n        fanIn = shape[0];\n        fanOut = shape[1];\n    }\n    else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n        if (dataFormat === 'channelsFirst') {\n            var receptiveFieldSize = math_utils_1.arrayProd(shape, 2);\n            fanIn = shape[1] * receptiveFieldSize;\n            fanOut = shape[0] * receptiveFieldSize;\n        }\n        else if (dataFormat === 'channelsLast') {\n            var receptiveFieldSize = math_utils_1.arrayProd(shape, 0, shape.length - 2);\n            fanIn = shape[shape.length - 2] * receptiveFieldSize;\n            fanOut = shape[shape.length - 1] * receptiveFieldSize;\n        }\n    }\n    else {\n        var shapeProd = math_utils_1.arrayProd(shape);\n        fanIn = Math.sqrt(shapeProd);\n        fanOut = Math.sqrt(shapeProd);\n    }\n    return [fanIn, fanOut];\n}\nvar VarianceScaling = /** @class */ (function (_super) {\n    __extends(VarianceScaling, _super);\n    /**\n     * Constructor of VarianceScaling.\n     * @throws ValueError for invalid value in scale.\n     */\n    function VarianceScaling(args) {\n        var _this = _super.call(this) || this;\n        if (args.scale < 0.0) {\n            throw new errors_1.ValueError(\"scale must be a positive float. Got: \" + args.scale);\n        }\n        _this.scale = args.scale == null ? 1.0 : args.scale;\n        _this.mode = args.mode == null ? 'fanIn' : args.mode;\n        checkFanMode(_this.mode);\n        _this.distribution =\n            args.distribution == null ? 'normal' : args.distribution;\n        checkDistribution(_this.distribution);\n        _this.seed = args.seed;\n        return _this;\n    }\n    VarianceScaling.prototype.apply = function (shape, dtype) {\n        var fans = computeFans(shape);\n        var fanIn = fans[0];\n        var fanOut = fans[1];\n        var scale = this.scale;\n        if (this.mode === 'fanIn') {\n            scale /= Math.max(1, fanIn);\n        }\n        else if (this.mode === 'fanOut') {\n            scale /= Math.max(1, fanOut);\n        }\n        else {\n            scale /= Math.max(1, (fanIn + fanOut) / 2);\n        }\n        if (this.distribution === 'normal') {\n            var stddev = Math.sqrt(scale);\n            dtype = dtype || 'float32';\n            if (dtype !== 'float32' && dtype !== 'int32') {\n                throw new errors_1.NotImplementedError(this.getClassName() + \" does not support dType \" + dtype + \".\");\n            }\n            return tfjs_core_1.truncatedNormal(shape, 0, stddev, dtype, this.seed);\n        }\n        else {\n            var limit = Math.sqrt(3 * scale);\n            return tfjs_core_1.randomUniform(shape, -limit, limit, dtype);\n        }\n    };\n    VarianceScaling.prototype.getConfig = function () {\n        return {\n            scale: this.scale,\n            mode: this.mode,\n            distribution: this.distribution,\n            seed: this.seed\n        };\n    };\n    /** @nocollapse */\n    VarianceScaling.className = 'VarianceScaling';\n    return VarianceScaling;\n}(Initializer));\nexports.VarianceScaling = VarianceScaling;\ntfjs_core_1.serialization.registerClass(VarianceScaling);\nvar GlorotUniform = /** @class */ (function (_super) {\n    __extends(GlorotUniform, _super);\n    /**\n     * Constructor of GlorotUniform\n     * @param scale\n     * @param mode\n     * @param distribution\n     * @param seed\n     */\n    function GlorotUniform(args) {\n        return _super.call(this, {\n            scale: 1.0,\n            mode: 'fanAvg',\n            distribution: 'uniform',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    GlorotUniform.prototype.getClassName = function () {\n        // In Python Keras, GlorotUniform is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    GlorotUniform.className = 'GlorotUniform';\n    return GlorotUniform;\n}(VarianceScaling));\nexports.GlorotUniform = GlorotUniform;\ntfjs_core_1.serialization.registerClass(GlorotUniform);\nvar GlorotNormal = /** @class */ (function (_super) {\n    __extends(GlorotNormal, _super);\n    /**\n     * Constructor of GlorotNormal.\n     * @param scale\n     * @param mode\n     * @param distribution\n     * @param seed\n     */\n    function GlorotNormal(args) {\n        return _super.call(this, {\n            scale: 1.0,\n            mode: 'fanAvg',\n            distribution: 'normal',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    GlorotNormal.prototype.getClassName = function () {\n        // In Python Keras, GlorotNormal is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    GlorotNormal.className = 'GlorotNormal';\n    return GlorotNormal;\n}(VarianceScaling));\nexports.GlorotNormal = GlorotNormal;\ntfjs_core_1.serialization.registerClass(GlorotNormal);\nvar HeNormal = /** @class */ (function (_super) {\n    __extends(HeNormal, _super);\n    function HeNormal(args) {\n        return _super.call(this, {\n            scale: 2.0,\n            mode: 'fanIn',\n            distribution: 'normal',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    HeNormal.prototype.getClassName = function () {\n        // In Python Keras, HeNormal is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    HeNormal.className = 'HeNormal';\n    return HeNormal;\n}(VarianceScaling));\nexports.HeNormal = HeNormal;\ntfjs_core_1.serialization.registerClass(HeNormal);\nvar HeUniform = /** @class */ (function (_super) {\n    __extends(HeUniform, _super);\n    function HeUniform(args) {\n        return _super.call(this, {\n            scale: 2.0,\n            mode: 'fanIn',\n            distribution: 'uniform',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    HeUniform.prototype.getClassName = function () {\n        // In Python Keras, HeUniform is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    HeUniform.className = 'HeUniform';\n    return HeUniform;\n}(VarianceScaling));\nexports.HeUniform = HeUniform;\ntfjs_core_1.serialization.registerClass(HeUniform);\nvar LeCunNormal = /** @class */ (function (_super) {\n    __extends(LeCunNormal, _super);\n    function LeCunNormal(args) {\n        return _super.call(this, {\n            scale: 1.0,\n            mode: 'fanIn',\n            distribution: 'normal',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    LeCunNormal.prototype.getClassName = function () {\n        // In Python Keras, LeCunNormal is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    LeCunNormal.className = 'LeCunNormal';\n    return LeCunNormal;\n}(VarianceScaling));\nexports.LeCunNormal = LeCunNormal;\ntfjs_core_1.serialization.registerClass(LeCunNormal);\nvar LeCunUniform = /** @class */ (function (_super) {\n    __extends(LeCunUniform, _super);\n    function LeCunUniform(args) {\n        return _super.call(this, {\n            scale: 1.0,\n            mode: 'fanIn',\n            distribution: 'uniform',\n            seed: args == null ? null : args.seed\n        }) || this;\n    }\n    LeCunUniform.prototype.getClassName = function () {\n        // In Python Keras, LeCunUniform is not a class, but a helper method\n        // that creates a VarianceScaling object. Use 'VarianceScaling' as\n        // class name to be compatible with that.\n        return VarianceScaling.className;\n    };\n    /** @nocollapse */\n    LeCunUniform.className = 'LeCunNormal';\n    return LeCunUniform;\n}(VarianceScaling));\nexports.LeCunUniform = LeCunUniform;\ntfjs_core_1.serialization.registerClass(LeCunUniform);\nvar Orthogonal = /** @class */ (function (_super) {\n    __extends(Orthogonal, _super);\n    function Orthogonal(args) {\n        var _this = _super.call(this) || this;\n        _this.DEFAULT_GAIN = 1;\n        _this.gain = args.gain == null ? _this.DEFAULT_GAIN : args.gain;\n        _this.seed = args.seed;\n        if (_this.seed != null) {\n            throw new errors_1.NotImplementedError('Random seed is not implemented for Orthogonal Initializer yet.');\n        }\n        return _this;\n    }\n    Orthogonal.prototype.apply = function (shape, dtype) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            if (shape.length !== 2) {\n                throw new errors_1.NotImplementedError('The Orthogonal Initializer does not support non-2D shapes yet.');\n            }\n            if (shape[0] * shape[1] > 2000) {\n                console.warn(\"Orthogonal initializer is being called on a matrix with more \" +\n                    (\"than 2000 (\" + shape[0] * shape[1] + \") elements: \") +\n                    \"Slowness may result.\");\n            }\n            // TODO(cais): Add seed support.\n            var normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n            var a = K.randomNormal(normalizedShape, 0, 1, 'float32');\n            var q = tfjs_core_1.linalg.gramSchmidt(a);\n            if (shape[0] > shape[1]) {\n                q = q.transpose();\n            }\n            return tfjs_core_1.mul(_this.gain, q);\n        });\n    };\n    Orthogonal.prototype.getConfig = function () {\n        return {\n            gain: this.gain,\n            seed: this.seed,\n        };\n    };\n    /** @nocollapse */\n    Orthogonal.className = 'Orthogonal';\n    return Orthogonal;\n}(Initializer));\nexports.Orthogonal = Orthogonal;\ntfjs_core_1.serialization.registerClass(Orthogonal);\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexports.INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n    'constant': 'Constant',\n    'glorotNormal': 'GlorotNormal',\n    'glorotUniform': 'GlorotUniform',\n    'heNormal': 'HeNormal',\n    'heUniform': 'HeUniform',\n    'identity': 'Identity',\n    'leCunNormal': 'LeCunNormal',\n    'leCunUniform': 'LeCunUniform',\n    'ones': 'Ones',\n    'orthogonal': 'Orthogonal',\n    'randomNormal': 'RandomNormal',\n    'randomUniform': 'RandomUniform',\n    'truncatedNormal': 'TruncatedNormal',\n    'varianceScaling': 'VarianceScaling',\n    'zeros': 'Zeros'\n};\nfunction deserializeInitializer(config, customObjects) {\n    if (customObjects === void 0) { customObjects = {}; }\n    return generic_utils_1.deserializeKerasObject(config, tfjs_core_1.serialization.SerializationMap.getMap().classNameMap, customObjects, 'initializer');\n}\nfunction serializeInitializer(initializer) {\n    return generic_utils_1.serializeKerasObject(initializer);\n}\nexports.serializeInitializer = serializeInitializer;\nfunction getInitializer(identifier) {\n    if (typeof identifier === 'string') {\n        var className = identifier in exports.INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n            exports.INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n            identifier;\n        /* We have four 'helper' classes for common initializers that\n        all get serialized as 'VarianceScaling' and shouldn't go through\n        the deserializeInitializer pathway. */\n        if (className === 'GlorotNormal') {\n            return new GlorotNormal();\n        }\n        else if (className === 'GlorotUniform') {\n            return new GlorotUniform();\n        }\n        else if (className === 'HeNormal') {\n            return new HeNormal();\n        }\n        else if (className === 'HeUniform') {\n            return new HeUniform();\n        }\n        else if (className === 'LeCunNormal') {\n            return new LeCunNormal();\n        }\n        else if (className === 'LeCunUniform') {\n            return new LeCunUniform();\n        }\n        else {\n            var config = {};\n            config['className'] = className;\n            config['config'] = {};\n            return deserializeInitializer(config);\n        }\n    }\n    else if (identifier instanceof Initializer) {\n        return identifier;\n    }\n    else {\n        return deserializeInitializer(identifier);\n    }\n}\nexports.getInitializer = getInitializer;\n"},"sourceMaps":{"js":{"version":3,"file":"initializers.js","sourceRoot":"","sources":["../src/initializers.ts"],"names":[],"mappings":";AAAA;;;;;;;;GAQG;;;;;;;;;;;;;;;AAEH,mDAA6J;AAE7J,0CAA4C;AAC5C,mCAAyC;AACzC,mCAAyD;AAEzD,wEAA0H;AAC1H,uDAA8G;AAC9G,iDAA6C;AAE7C,SAAgB,YAAY,CAAC,KAAc;IACzC,yCAAyB,CAAC,0CAAqB,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;AACrE,CAAC;AAFD,oCAEC;AAED,SAAgB,iBAAiB,CAAC,KAAc;IAC9C,yCAAyB,CAAC,8CAAyB,EAAE,cAAc,EAAE,KAAK,CAAC,CAAC;AAC9E,CAAC;AAFD,8CAEC;AAED;;;;;GAKG;AACH;IAA0C,+BAA0B;IAApE;;IAeA,CAAC;IAdQ,iDAA2B,GAAlC;QACE,OAAO,KAAK,CAAC;IACf,CAAC;IASD,+BAAS,GAAT;QACE,OAAO,EAAE,CAAC;IACZ,CAAC;IACH,kBAAC;AAAD,CAAC,AAfD,CAA0C,yBAAa,CAAC,YAAY,GAenE;AAfqB,kCAAW;AAiBjC;IAA2B,yBAAW;IAAtC;;IAOA,CAAC;IAHC,qBAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,OAAO,iBAAK,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;IAC7B,CAAC;IALD,kBAAkB;IACX,eAAS,GAAG,OAAO,CAAC;IAK7B,YAAC;CAAA,AAPD,CAA2B,WAAW,GAOrC;AAPY,sBAAK;AAQlB,yBAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AAEnC;IAA0B,wBAAW;IAArC;;IAOA,CAAC;IAHC,oBAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,OAAO,gBAAI,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;IAC5B,CAAC;IALD,kBAAkB;IACX,cAAS,GAAG,MAAM,CAAC;IAK5B,WAAC;CAAA,AAPD,CAA0B,WAAW,GAOpC;AAPY,oBAAI;AAQjB,yBAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AAOlC;IAA8B,4BAAW;IAIvC,kBAAY,IAAkB;QAA9B,YACE,iBAAO,SASR;QARC,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;YAC5B,MAAM,IAAI,mBAAU,CAChB,sDAAoD,IAAM,CAAC,CAAC;SACjE;QACD,IAAI,IAAI,CAAC,KAAK,KAAK,SAAS,EAAE;YAC5B,MAAM,IAAI,mBAAU,CAAC,wCAAsC,IAAM,CAAC,CAAC;SACpE;QACD,KAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;;IAC1B,CAAC;IAED,wBAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAApC,iBAEC;QADC,OAAO,gBAAI,CAAC,cAAM,OAAA,eAAG,CAAC,kBAAM,CAAC,KAAI,CAAC,KAAK,CAAC,EAAE,gBAAI,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,EAA3C,CAA2C,CAAC,CAAC;IACjE,CAAC;IAED,4BAAS,GAAT;QACE,OAAO;YACL,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC;IACJ,CAAC;IAvBD,kBAAkB;IACX,kBAAS,GAAG,UAAU,CAAC;IAuBhC,eAAC;CAAA,AAzBD,CAA8B,WAAW,GAyBxC;AAzBY,4BAAQ;AA0BrB,yBAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAWtC;IAAmC,iCAAW;IAS5C,uBAAY,IAAuB;QAAnC,YACE,iBAAO,SAIR;QAXQ,oBAAc,GAAG,CAAC,IAAI,CAAC;QACvB,oBAAc,GAAG,IAAI,CAAC;QAO7B,KAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,KAAI,CAAC,cAAc,CAAC;QACjD,KAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,KAAI,CAAC,cAAc,CAAC;QACjD,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;;IACxB,CAAC;IAED,6BAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,OAAO,yBAAa,CAAC,KAAK,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;IAC/D,CAAC;IAED,iCAAS,GAAT;QACE,OAAO,EAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;IACrE,CAAC;IArBD,kBAAkB;IACX,uBAAS,GAAG,eAAe,CAAC;IAqBrC,oBAAC;CAAA,AAvBD,CAAmC,WAAW,GAuB7C;AAvBY,sCAAa;AAwB1B,yBAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;AAW3C;IAAkC,gCAAW;IAS3C,sBAAY,IAAsB;QAAlC,YACE,iBAAO,SAIR;QAXQ,kBAAY,GAAG,EAAE,CAAC;QAClB,oBAAc,GAAG,IAAI,CAAC;QAO7B,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,KAAI,CAAC,YAAY,CAAC;QAC3C,KAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,KAAI,CAAC,cAAc,CAAC;QACjD,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;;IACxB,CAAC;IAED,4BAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;QAC3B,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,EAAE;YAC5C,MAAM,IAAI,4BAAmB,CACzB,yCAAuC,KAAK,MAAG,CAAC,CAAC;SACtD;QAED,OAAO,CAAC,CAAC,YAAY,CAAC,KAAK,EAAE,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IACzE,CAAC;IAED,gCAAS,GAAT;QACE,OAAO,EAAC,IAAI,EAAE,IAAI,CAAC,IAAI,EAAE,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;IACjE,CAAC;IA3BD,kBAAkB;IACX,sBAAS,GAAG,cAAc,CAAC;IA2BpC,mBAAC;CAAA,AA7BD,CAAkC,WAAW,GA6B5C;AA7BY,oCAAY;AA8BzB,yBAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAW1C;IAAqC,mCAAW;IAU9C,yBAAY,IAAyB;QAArC,YACE,iBAAO,SAIR;QAXQ,kBAAY,GAAG,EAAE,CAAC;QAClB,oBAAc,GAAG,IAAI,CAAC;QAO7B,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,KAAI,CAAC,YAAY,CAAC;QAC3C,KAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,KAAI,CAAC,cAAc,CAAC;QACjD,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;;IACxB,CAAC;IAED,+BAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;QAC3B,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,EAAE;YAC5C,MAAM,IAAI,4BAAmB,CACzB,4CAA0C,KAAK,MAAG,CAAC,CAAC;SACzD;QACD,OAAO,2BAAe,CAAC,KAAK,EAAE,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IAC1E,CAAC;IAED,mCAAS,GAAT;QACE,OAAO,EAAC,IAAI,EAAE,IAAI,CAAC,IAAI,EAAE,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;IACjE,CAAC;IA3BD,kBAAkB;IACX,yBAAS,GAAG,iBAAiB,CAAC;IA2BvC,sBAAC;CAAA,AA7BD,CAAqC,WAAW,GA6B/C;AA7BY,0CAAe;AA8B5B,yBAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAS7C;IAA8B,4BAAW;IAIvC,kBAAY,IAAkB;QAA9B,YACE,iBAAO,SAER;QADC,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC;;IAClD,CAAC;IAED,wBAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAApC,iBAUC;QATC,OAAO,gBAAI,CAAC;YACV,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,CAAC,EAAE;gBAC/C,MAAM,IAAI,mBAAU,CAChB,kDAAkD;oBAClD,sBAAsB,CAAC,CAAC;aAC7B;iBAAM;gBACL,OAAO,eAAG,CAAC,KAAI,CAAC,IAAI,EAAE,eAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aACtC;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED,4BAAS,GAAT;QACE,OAAO,EAAC,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;IAC3B,CAAC;IAtBD,kBAAkB;IACX,kBAAS,GAAG,UAAU,CAAC;IAsBhC,eAAC;CAAA,AAxBD,CAA8B,WAAW,GAwBxC;AAxBY,4BAAQ;AAyBrB,yBAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAEtC;;;;;;;GAOG;AACH,SAAS,WAAW,CAChB,KAAY,EAAE,UAAuC;IAAvC,2BAAA,EAAA,2BAAuC;IACvD,IAAI,KAAa,CAAC;IAClB,IAAI,MAAc,CAAC;IACnB,wBAAe,CAAC,UAAU,CAAC,CAAC;IAC5B,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;QACtB,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;QACjB,MAAM,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;KACnB;SAAM,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE;QACjD,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,IAAM,kBAAkB,GAAG,sBAAS,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;YAC/C,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,kBAAkB,CAAC;YACtC,MAAM,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,kBAAkB,CAAC;SACxC;aAAM,IAAI,UAAU,KAAK,cAAc,EAAE;YACxC,IAAM,kBAAkB,GAAG,sBAAS,CAAC,KAAK,EAAE,CAAC,EAAE,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YACjE,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,kBAAkB,CAAC;YACrD,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,kBAAkB,CAAC;SACvD;KACF;SAAM;QACL,IAAM,SAAS,GAAG,sBAAS,CAAC,KAAK,CAAC,CAAC;QACnC,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QAC7B,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;KAC/B;IAED,OAAO,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;AACzB,CAAC;AAgBD;IAAqC,mCAAW;IAQ9C;;;OAGG;IACH,yBAAY,IAAyB;QAArC,YACE,iBAAO,SAYR;QAXC,IAAI,IAAI,CAAC,KAAK,GAAG,GAAG,EAAE;YACpB,MAAM,IAAI,mBAAU,CAChB,0CAAwC,IAAI,CAAC,KAAO,CAAC,CAAC;SAC3D;QACD,KAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;QACnD,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;QACpD,YAAY,CAAC,KAAI,CAAC,IAAI,CAAC,CAAC;QACxB,KAAI,CAAC,YAAY;YACb,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC;QAC7D,iBAAiB,CAAC,KAAI,CAAC,YAAY,CAAC,CAAC;QACrC,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;;IACxB,CAAC;IAED,+BAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAClC,IAAM,IAAI,GAAG,WAAW,CAAC,KAAK,CAAC,CAAC;QAChC,IAAM,KAAK,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACtB,IAAM,MAAM,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACvB,IAAI,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACvB,IAAI,IAAI,CAAC,IAAI,KAAK,OAAO,EAAE;YACzB,KAAK,IAAI,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;SAC7B;aAAM,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YACjC,KAAK,IAAI,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;SAC9B;aAAM;YACL,KAAK,IAAI,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,KAAK,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;SAC5C;QAED,IAAI,IAAI,CAAC,YAAY,KAAK,QAAQ,EAAE;YAClC,IAAM,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAChC,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;YAC3B,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,EAAE;gBAC5C,MAAM,IAAI,4BAAmB,CACtB,IAAI,CAAC,YAAY,EAAE,gCAA2B,KAAK,MAAG,CAAC,CAAC;aAChE;YACD,OAAO,2BAAe,CAAC,KAAK,EAAE,CAAC,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;SAC5D;aAAM;YACL,IAAM,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC;YACnC,OAAO,yBAAa,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;SACnD;IACH,CAAC;IAED,mCAAS,GAAT;QACE,OAAO;YACL,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,YAAY,EAAE,IAAI,CAAC,YAAY;YAC/B,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;IACJ,CAAC;IA5DD,kBAAkB;IACX,yBAAS,GAAG,iBAAiB,CAAC;IA4DvC,sBAAC;CAAA,AA9DD,CAAqC,WAAW,GA8D/C;AA9DY,0CAAe;AA+D5B,yBAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAO7C;IAAmC,iCAAe;IAIhD;;;;;;OAMG;IACH,uBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,QAAQ;YACd,YAAY,EAAE,SAAS;YACvB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,oCAAY,GAAZ;QACE,qEAAqE;QACrE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAxBD,kBAAkB;IACX,uBAAS,GAAG,eAAe,CAAC;IAwBrC,oBAAC;CAAA,AA1BD,CAAmC,eAAe,GA0BjD;AA1BY,sCAAa;AA2B1B,yBAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;AAE3C;IAAkC,gCAAe;IAI/C;;;;;;OAMG;IACH,sBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,QAAQ;YACd,YAAY,EAAE,QAAQ;YACtB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,mCAAY,GAAZ;QACE,oEAAoE;QACpE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAxBD,kBAAkB;IACX,sBAAS,GAAG,cAAc,CAAC;IAwBpC,mBAAC;CAAA,AA1BD,CAAkC,eAAe,GA0BhD;AA1BY,oCAAY;AA2BzB,yBAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C;IAA8B,4BAAe;IAI3C,kBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,OAAO;YACb,YAAY,EAAE,QAAQ;YACtB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,+BAAY,GAAZ;QACE,gEAAgE;QAChE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAjBD,kBAAkB;IACX,kBAAS,GAAG,UAAU,CAAC;IAiBhC,eAAC;CAAA,AAnBD,CAA8B,eAAe,GAmB5C;AAnBY,4BAAQ;AAoBrB,yBAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAEtC;IAA+B,6BAAe;IAI5C,mBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,OAAO;YACb,YAAY,EAAE,SAAS;YACvB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,gCAAY,GAAZ;QACE,iEAAiE;QACjE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAjBD,kBAAkB;IACX,mBAAS,GAAG,WAAW,CAAC;IAiBjC,gBAAC;CAAA,AAnBD,CAA+B,eAAe,GAmB7C;AAnBY,8BAAS;AAoBtB,yBAAa,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC;AAEvC;IAAiC,+BAAe;IAI9C,qBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,OAAO;YACb,YAAY,EAAE,QAAQ;YACtB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,kCAAY,GAAZ;QACE,mEAAmE;QACnE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAjBD,kBAAkB;IACX,qBAAS,GAAG,aAAa,CAAC;IAiBnC,kBAAC;CAAA,AAnBD,CAAiC,eAAe,GAmB/C;AAnBY,kCAAW;AAoBxB,yBAAa,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;AAEzC;IAAkC,gCAAe;IAI/C,sBAAY,IAA8B;eACxC,kBAAM;YACJ,KAAK,EAAE,GAAG;YACV,IAAI,EAAE,OAAO;YACb,YAAY,EAAE,SAAS;YACvB,IAAI,EAAE,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI;SACtC,CAAC;IACJ,CAAC;IAED,mCAAY,GAAZ;QACE,oEAAoE;QACpE,kEAAkE;QAClE,yCAAyC;QACzC,OAAO,eAAe,CAAC,SAAS,CAAC;IACnC,CAAC;IAjBD,kBAAkB;IACX,sBAAS,GAAG,aAAa,CAAC;IAiBnC,mBAAC;CAAA,AAnBD,CAAkC,eAAe,GAmBhD;AAnBY,oCAAY;AAoBzB,yBAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAS1C;IAAgC,8BAAW;IAOzC,oBAAY,IAAqB;QAAjC,YACE,iBAAO,SAQR;QAbQ,kBAAY,GAAG,CAAC,CAAC;QAMxB,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,KAAI,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;QAC9D,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QAEtB,IAAI,KAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,4BAAmB,CACzB,gEAAgE,CAAC,CAAC;SACvE;;IACH,CAAC;IAED,0BAAK,GAAL,UAAM,KAAY,EAAE,KAAgB;QAApC,iBAuBC;QAtBC,OAAO,gBAAI,CAAC;YACV,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;gBACtB,MAAM,IAAI,4BAAmB,CACzB,gEAAgE,CAAC,CAAC;aACvE;YACD,IAAI,KAAK,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE;gBAC9B,OAAO,CAAC,IAAI,CACR,+DAA+D;qBAC/D,gBAAc,KAAK,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,iBAAc,CAAA;oBAC/C,sBAAsB,CAAC,CAAC;aAC7B;YAED,gCAAgC;YAChC,IAAM,eAAe,GACjB,KAAK,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;YACvD,IAAM,CAAC,GAAG,CAAC,CAAC,YAAY,CAAC,eAAe,EAAE,CAAC,EAAE,CAAC,EAAE,SAAS,CAAa,CAAC;YACvE,IAAI,CAAC,GAAG,kBAAM,CAAC,WAAW,CAAC,CAAC,CAAa,CAAC;YAC1C,IAAI,KAAK,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE;gBACvB,CAAC,GAAG,CAAC,CAAC,SAAS,EAAE,CAAC;aACnB;YACD,OAAO,eAAG,CAAC,KAAI,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;QAC3B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,8BAAS,GAAT;QACE,OAAO;YACL,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;IACJ,CAAC;IA/CD,kBAAkB;IACX,oBAAS,GAAG,YAAY,CAAC;IA+ClC,iBAAC;CAAA,AAjDD,CAAgC,WAAW,GAiD1C;AAjDY,gCAAU;AAkDvB,yBAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;AAQxC,yEAAyE;AACzE,WAAW;AACE,QAAA,0CAA0C,GACD;IAChD,UAAU,EAAE,UAAU;IACtB,cAAc,EAAE,cAAc;IAC9B,eAAe,EAAE,eAAe;IAChC,UAAU,EAAE,UAAU;IACtB,WAAW,EAAE,WAAW;IACxB,UAAU,EAAE,UAAU;IACtB,aAAa,EAAE,aAAa;IAC5B,cAAc,EAAE,cAAc;IAC9B,MAAM,EAAE,MAAM;IACd,YAAY,EAAE,YAAY;IAC1B,cAAc,EAAE,cAAc;IAC9B,eAAe,EAAE,eAAe;IAChC,iBAAiB,EAAE,iBAAiB;IACpC,iBAAiB,EAAE,iBAAiB;IACpC,OAAO,EAAE,OAAO;CACjB,CAAC;AAEN,SAAS,sBAAsB,CAC3B,MAAgC,EAChC,aAA4C;IAA5C,8BAAA,EAAA,kBAA4C;IAC9C,OAAO,sCAAsB,CACzB,MAAM,EAAE,yBAAa,CAAC,gBAAgB,CAAC,MAAM,EAAE,CAAC,YAAY,EAC5D,aAAa,EAAE,aAAa,CAAC,CAAC;AACpC,CAAC;AAED,SAAgB,oBAAoB,CAAC,WAAwB;IAE3D,OAAO,oCAAoB,CAAC,WAAW,CAAC,CAAC;AAC3C,CAAC;AAHD,oDAGC;AAED,SAAgB,cAAc,CAAC,UACwB;IACrD,IAAI,OAAO,UAAU,KAAK,QAAQ,EAAE;QAClC,IAAM,SAAS,GAAG,UAAU,IAAI,kDAA0C,CAAC,CAAC;YACxE,kDAA0C,CAAC,UAAU,CAAC,CAAC,CAAC;YACxD,UAAU,CAAC;QACf;;8CAEsC;QACtC,IAAI,SAAS,KAAK,cAAc,EAAE;YAChC,OAAO,IAAI,YAAY,EAAE,CAAC;SAC3B;aAAM,IAAI,SAAS,KAAK,eAAe,EAAE;YACxC,OAAO,IAAI,aAAa,EAAE,CAAC;SAC5B;aAAM,IAAI,SAAS,KAAK,UAAU,EAAE;YACnC,OAAO,IAAI,QAAQ,EAAE,CAAC;SACvB;aAAM,IAAI,SAAS,KAAK,WAAW,EAAE;YACpC,OAAO,IAAI,SAAS,EAAE,CAAC;SACxB;aAAM,IAAI,SAAS,KAAK,aAAa,EAAE;YACtC,OAAO,IAAI,WAAW,EAAE,CAAC;SAC1B;aAAM,IAAI,SAAS,KAAK,cAAc,EAAE;YACvC,OAAO,IAAI,YAAY,EAAE,CAAC;SAC3B;aAAM;YACL,IAAM,MAAM,GAA6B,EAAE,CAAC;YAC5C,MAAM,CAAC,WAAW,CAAC,GAAG,SAAS,CAAC;YAChC,MAAM,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC;YACtB,OAAO,sBAAsB,CAAC,MAAM,CAAC,CAAC;SACvC;KACF;SAAM,IAAI,UAAU,YAAY,WAAW,EAAE;QAC5C,OAAO,UAAU,CAAC;KACnB;SAAM;QACL,OAAO,sBAAsB,CAAC,UAAU,CAAC,CAAC;KAC3C;AACH,CAAC;AAhCD,wCAgCC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, eye, linalg, mul, ones, randomUniform, scalar, serialization, Tensor, Tensor2D, tidy, truncatedNormal, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from './backend/tfjs_backend';\nimport {checkDataFormat} from './common';\nimport {NotImplementedError, ValueError} from './errors';\nimport {DataFormat, Shape} from './keras_format/common';\nimport {Distribution, FanMode, VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES} from './keras_format/initializer_config';\nimport {checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject} from './utils/generic_utils';\nimport {arrayProd} from './utils/math_utils';\n\nexport function checkFanMode(value?: string): void {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\n\nexport function checkDistribution(value?: string): void {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport abstract class Initializer extends serialization.Serializable {\n  public fromConfigUsesCustomObjects(): boolean {\n    return false;\n  }\n  /**\n   * Generate an initial value.\n   * @param shape\n   * @param dtype\n   * @return The init value.\n   */\n  abstract apply(shape: Shape, dtype?: DataType): Tensor;\n\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\nexport class Zeros extends Initializer {\n  /** @nocollapse */\n  static className = 'Zeros';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return zeros(shape, dtype);\n  }\n}\nserialization.registerClass(Zeros);\n\nexport class Ones extends Initializer {\n  /** @nocollapse */\n  static className = 'Ones';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return ones(shape, dtype);\n  }\n}\nserialization.registerClass(Ones);\n\nexport interface ConstantArgs {\n  /** The value for each element in the variable. */\n  value: number;\n}\n\nexport class Constant extends Initializer {\n  /** @nocollapse */\n  static className = 'Constant';\n  private value: number;\n  constructor(args: ConstantArgs) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(\n          `Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      value: this.value,\n    };\n  }\n}\nserialization.registerClass(Constant);\n\nexport interface RandomUniformArgs {\n  /** Lower bound of the range of random values to generate. */\n  minval?: number;\n  /** Upper bound of the range of random values to generate. */\n  maxval?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomUniform extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomUniform';\n  readonly DEFAULT_MINVAL = -0.05;\n  readonly DEFAULT_MAXVAL = 0.05;\n  private minval: number;\n  private maxval: number;\n  private seed: number;\n\n  constructor(args: RandomUniformArgs) {\n    super();\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return randomUniform(shape, this.minval, this.maxval, dtype);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {minval: this.minval, maxval: this.maxval, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomUniform);\n\nexport interface RandomNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomNormal';\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: RandomNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomNormal);\n\nexport interface TruncatedNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class TruncatedNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'TruncatedNormal';\n\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: TruncatedNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(TruncatedNormal);\n\nexport interface IdentityArgs {\n  /**\n   * Multiplicative factor to apply to the identity matrix.\n   */\n  gain?: number;\n}\n\nexport class Identity extends Initializer {\n  /** @nocollapse */\n  static className = 'Identity';\n  private gain: number;\n  constructor(args: IdentityArgs) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError(\n            'Identity matrix initializer can only be used for' +\n            ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {gain: this.gain};\n  }\n}\nserialization.registerClass(Identity);\n\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(\n    shape: Shape, dataFormat: DataFormat = 'channelsLast'): number[] {\n  let fanIn: number;\n  let fanOut: number;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport interface VarianceScalingArgs {\n  /** Scaling factor (positive float). */\n  scale?: number;\n\n  /** Fanning mode for inputs and outputs. */\n  mode?: FanMode;\n\n  /** Probabilistic distribution of the values. */\n  distribution?: Distribution;\n\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class VarianceScaling extends Initializer {\n  /** @nocollapse */\n  static className = 'VarianceScaling';\n  private scale: number;\n  private mode: FanMode;\n  private distribution: Distribution;\n  private seed: number;\n\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args: VarianceScalingArgs) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(\n          `scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution =\n        args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\n            `${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype);\n    }\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\nserialization.registerClass(VarianceScaling);\n\nexport interface SeedOnlyInitializerArgs {\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class GlorotUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotUniform';\n\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotUniform);\n\nexport class GlorotNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotNormal';\n\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotNormal);\n\nexport class HeNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeNormal);\n\nexport class HeUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeUniform);\n\nexport class LeCunNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunNormal);\n\nexport class LeCunUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunUniform);\n\nexport interface OrthogonalArgs extends SeedOnlyInitializerArgs {\n  /**\n   * Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.\n   */\n  gain?: number;\n}\n\nexport class Orthogonal extends Initializer {\n  /** @nocollapse */\n  static className = 'Orthogonal';\n  readonly DEFAULT_GAIN = 1;\n  protected readonly gain: number;\n  protected readonly seed: number;\n\n  constructor(args?: OrthogonalArgs) {\n    super();\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError(\n          'Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2) {\n        throw new NotImplementedError(\n            'The Orthogonal Initializer does not support non-2D shapes yet.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(\n            `Orthogonal initializer is being called on a matrix with more ` +\n            `than 2000 (${shape[0] * shape[1]}) elements: ` +\n            `Slowness may result.`);\n      }\n\n      // TODO(cais): Add seed support.\n      const normalizedShape =\n          shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32') as Tensor2D;\n      let q = linalg.gramSchmidt(a) as Tensor2D;\n      if (shape[0] > shape[1]) {\n        q = q.transpose();\n      }\n      return mul(this.gain, q);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      gain: this.gain,\n      seed: this.seed,\n    };\n  }\n}\nserialization.registerClass(Orthogonal);\n\n/** @docinline */\nexport type InitializerIdentifier =\n    'constant'|'glorotNormal'|'glorotUniform'|'heNormal'|'heUniform'|'identity'|\n    'leCunNormal'|'leCunUniform'|'ones'|'orthogonal'|'randomNormal'|\n    'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string;\n\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP:\n    {[identifier in InitializerIdentifier]: string} = {\n      'constant': 'Constant',\n      'glorotNormal': 'GlorotNormal',\n      'glorotUniform': 'GlorotUniform',\n      'heNormal': 'HeNormal',\n      'heUniform': 'HeUniform',\n      'identity': 'Identity',\n      'leCunNormal': 'LeCunNormal',\n      'leCunUniform': 'LeCunUniform',\n      'ones': 'Ones',\n      'orthogonal': 'Orthogonal',\n      'randomNormal': 'RandomNormal',\n      'randomUniform': 'RandomUniform',\n      'truncatedNormal': 'TruncatedNormal',\n      'varianceScaling': 'VarianceScaling',\n      'zeros': 'Zeros'\n    };\n\nfunction deserializeInitializer(\n    config: serialization.ConfigDict,\n    customObjects: serialization.ConfigDict = {}): Initializer {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer: Initializer):\n    serialization.ConfigDictValue {\n  return serializeKerasObject(initializer);\n}\n\nexport function getInitializer(identifier: InitializerIdentifier|Initializer|\n                               serialization.ConfigDict): Initializer {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n        INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n        identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config: serialization.ConfigDict = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}\n"]}},"error":null,"hash":"55170783f4878b0d8c5431948395f7e4","cacheData":{"env":{}}}