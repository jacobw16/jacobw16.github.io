{"id":"node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","dependencies":[{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js.map","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\src\\engine\\training_tensors.ts","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\package.json","includedInParent":true,"mtime":1582861032163},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1581030261368},{"name":"@tensorflow/tfjs-core","loc":{"line":51,"column":26},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.esm.js"},{"name":"../backend/tfjs_backend","loc":{"line":52,"column":29},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\backend\\tfjs_backend.js"},{"name":"../base_callbacks","loc":{"line":53,"column":31},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\base_callbacks.js"},{"name":"../errors","loc":{"line":54,"column":23},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\errors.js"},{"name":"../logs","loc":{"line":55,"column":21},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\logs.js"},{"name":"../utils/math_utils","loc":{"line":56,"column":27},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\training_tensors.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\math_utils.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nvar tfc = require(\"@tensorflow/tfjs-core\");\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar tfjs_backend_1 = require(\"../backend/tfjs_backend\");\nvar base_callbacks_1 = require(\"../base_callbacks\");\nvar errors_1 = require(\"../errors\");\nvar logs_1 = require(\"../logs\");\nvar math_utils_1 = require(\"../utils/math_utils\");\nfunction checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), function () { return \"batchSize is required to be a positive integer, but got \" + batchSize; });\n}\nexports.checkBatchSize = checkBatchSize;\n/**\n * Slice an Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nfunction sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(function (array) { return tfjs_backend_1.sliceAlongFirstAxis(array, start, stop - start); });\n    }\n    else { // Tensor.\n        return tfjs_backend_1.sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\nexports.sliceArrays = sliceArrays;\n/**\n * Slice an Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nfunction sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(function () {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(function (array) { return sliceArraysByIndices(array, indices); });\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return tfjs_backend_1.gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\nexports.sliceArraysByIndices = sliceArraysByIndices;\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nfunction makeBatches(size, batchSize) {\n    var output = [];\n    var batchStart = 0;\n    var batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\nexports.makeBatches = makeBatches;\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown.\n * @param epochs Number of times to iterate over the data.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run).\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nfunction fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    return __awaiter(this, void 0, void 0, function () {\n        var doValidation, numTrainSamples, indexArray, _a, callbackList, history, _loop_1, epoch, state_1;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    if (batchSize == null) {\n                        batchSize = 32;\n                    }\n                    if (epochs == null) {\n                        epochs = 1;\n                    }\n                    if (shuffle == null) {\n                        shuffle = true;\n                    }\n                    if (initialEpoch == null) {\n                        initialEpoch = 0;\n                    }\n                    doValidation = false;\n                    if (valF != null && valIns != null) {\n                        doValidation = true;\n                        // TODO(cais): verbose message.\n                    }\n                    if (validationSteps != null) {\n                        doValidation = true;\n                        if (stepsPerEpoch == null) {\n                            throw new errors_1.ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                                'i.e., `stepsPerEpoch` must be set.');\n                        }\n                    }\n                    numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n                    if (numTrainSamples != null) {\n                        indexArray = math_utils_1.range(0, numTrainSamples);\n                    }\n                    if (verbose == null) {\n                        verbose = 1;\n                    }\n                    _a = base_callbacks_1.configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics), callbackList = _a.callbackList, history = _a.history;\n                    callbackList.setModel(model);\n                    model.history = history;\n                    return [4 /*yield*/, callbackList.onTrainBegin()];\n                case 1:\n                    _b.sent();\n                    model.stopTraining_ = false;\n                    _loop_1 = function (epoch) {\n                        var epochLogs, epochIndexArray1D_1, batches_1, _loop_2, batchIndex, state_2;\n                        return __generator(this, function (_a) {\n                            switch (_a.label) {\n                                case 0: return [4 /*yield*/, callbackList.onEpochBegin(epoch)];\n                                case 1:\n                                    _a.sent();\n                                    epochLogs = {};\n                                    if (!(stepsPerEpoch != null)) return [3 /*break*/, 2];\n                                    throw new errors_1.NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n                                case 2:\n                                    if (shuffle === 'batch') {\n                                        throw new errors_1.NotImplementedError('batch shuffling is not implemneted yet');\n                                    }\n                                    else if (shuffle) {\n                                        tfjs_core_1.util.shuffle(indexArray);\n                                    }\n                                    epochIndexArray1D_1 = tfjs_core_1.tensor1d(indexArray);\n                                    batches_1 = makeBatches(numTrainSamples, batchSize);\n                                    _loop_2 = function (batchIndex) {\n                                        var batchLogs;\n                                        return __generator(this, function (_a) {\n                                            switch (_a.label) {\n                                                case 0:\n                                                    batchLogs = {};\n                                                    return [4 /*yield*/, callbackList.onBatchBegin(batchIndex, batchLogs)];\n                                                case 1:\n                                                    _a.sent();\n                                                    tfc.tidy(function () {\n                                                        var batchStart = batches_1[batchIndex][0];\n                                                        var batchEnd = batches_1[batchIndex][1];\n                                                        var batchIds = tfjs_backend_1.sliceAlongFirstAxis(epochIndexArray1D_1, batchStart, batchEnd - batchStart);\n                                                        batchLogs['batch'] = batchIndex;\n                                                        batchLogs['size'] = batchEnd - batchStart;\n                                                        // TODO(cais): In ins, train flag can be a number, instead of an\n                                                        //   Tensor? Do we need to handle this in tfjs-layers?\n                                                        var insBatch = sliceArraysByIndices(ins, batchIds);\n                                                        var outs = f(insBatch);\n                                                        for (var i = 0; i < outLabels.length; ++i) {\n                                                            var label = outLabels[i];\n                                                            var out = outs[i];\n                                                            batchLogs[label] = out;\n                                                            tfc.keep(out);\n                                                            // TODO(cais): Use scope() to avoid ownership.\n                                                        }\n                                                        if (batchIndex === batches_1.length - 1) { // Last batch.\n                                                            if (doValidation) {\n                                                                var valOuts = model.testLoop(valF, valIns, batchSize);\n                                                                // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                                                                for (var i = 0; i < outLabels.length; ++i) {\n                                                                    var label = outLabels[i];\n                                                                    var out = valOuts[i];\n                                                                    tfc.keep(out);\n                                                                    // TODO(cais): Use scope() to avoid ownership.\n                                                                    epochLogs['val_' + label] = out;\n                                                                }\n                                                            }\n                                                        }\n                                                    });\n                                                    return [4 /*yield*/, callbackList.onBatchEnd(batchIndex, batchLogs)];\n                                                case 2:\n                                                    _a.sent();\n                                                    logs_1.disposeTensorsInLogs(batchLogs);\n                                                    if (model.stopTraining_) {\n                                                        return [2 /*return*/, \"break\"];\n                                                    }\n                                                    return [2 /*return*/];\n                                            }\n                                        });\n                                    };\n                                    batchIndex = 0;\n                                    _a.label = 3;\n                                case 3:\n                                    if (!(batchIndex < batches_1.length)) return [3 /*break*/, 6];\n                                    return [5 /*yield**/, _loop_2(batchIndex)];\n                                case 4:\n                                    state_2 = _a.sent();\n                                    if (state_2 === \"break\")\n                                        return [3 /*break*/, 6];\n                                    _a.label = 5;\n                                case 5:\n                                    ++batchIndex;\n                                    return [3 /*break*/, 3];\n                                case 6:\n                                    epochIndexArray1D_1.dispose();\n                                    _a.label = 7;\n                                case 7: \n                                // TODO(cais): Run validation at the end of the epoch.\n                                return [4 /*yield*/, callbackList.onEpochEnd(epoch, epochLogs)];\n                                case 8:\n                                    // TODO(cais): Run validation at the end of the epoch.\n                                    _a.sent();\n                                    if (model.stopTraining_) {\n                                        return [2 /*return*/, \"break\"];\n                                    }\n                                    return [2 /*return*/];\n                            }\n                        });\n                    };\n                    epoch = initialEpoch;\n                    _b.label = 2;\n                case 2:\n                    if (!(epoch < epochs)) return [3 /*break*/, 5];\n                    return [5 /*yield**/, _loop_1(epoch)];\n                case 3:\n                    state_1 = _b.sent();\n                    if (state_1 === \"break\")\n                        return [3 /*break*/, 5];\n                    _b.label = 4;\n                case 4:\n                    ++epoch;\n                    return [3 /*break*/, 2];\n                case 5: return [4 /*yield*/, callbackList.onTrainEnd()];\n                case 6:\n                    _b.sent();\n                    return [4 /*yield*/, model.history.syncData()];\n                case 7:\n                    _b.sent();\n                    return [2 /*return*/, model.history];\n            }\n        });\n    });\n}\nfunction fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args) {\n    if (args === void 0) { args = {}; }\n    return __awaiter(this, void 0, void 0, function () {\n        var inputs, targets, inputValX, inputValY, valX, valY, sampleWeights, batchSize, checkBatchAxis, standardizedOuts, doValidation, valIns, checkBatchAxis_1, valStandardized, splitAt, originalBatchSize, ins, trainFunction, outLabels, valFunction, callbackMetrics, callbacks, out;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    if (model.isTraining) {\n                        throw new Error('Cannot start training because another fit() call is ongoing.');\n                    }\n                    model.isTraining = true;\n                    _a.label = 1;\n                case 1:\n                    _a.trys.push([1, , 7, 8]);\n                    batchSize = args.batchSize == null ? 32 : args.batchSize;\n                    checkBatchSize(batchSize);\n                    checkBatchAxis = false;\n                    return [4 /*yield*/, model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize)];\n                case 2:\n                    standardizedOuts = _a.sent();\n                    inputs = standardizedOuts[0];\n                    targets = standardizedOuts[1];\n                    sampleWeights = standardizedOuts[2];\n                    doValidation = false;\n                    valIns = void 0;\n                    if (!(args.validationData != null && args.validationData.length > 0)) return [3 /*break*/, 4];\n                    doValidation = true;\n                    if (args.validationData.length === 2) {\n                        // config.validationData consists of valX and valY.\n                        inputValX = args.validationData[0];\n                        inputValY = args.validationData[1];\n                    }\n                    else if (args.validationData.length === 3) {\n                        throw new errors_1.NotImplementedError('validationData including sample weights is not supported yet.');\n                    }\n                    else {\n                        throw new errors_1.ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" +\n                            \"or 3 (valX, valY, valSampleWeight) items; \" +\n                            (args.validationData + \" is invalid.\"));\n                    }\n                    checkBatchAxis_1 = true;\n                    return [4 /*yield*/, model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis_1, batchSize)];\n                case 3:\n                    valStandardized = _a.sent();\n                    valX = valStandardized[0];\n                    valY = valStandardized[1];\n                    valIns = valX.concat(valY);\n                    return [3 /*break*/, 5];\n                case 4:\n                    if (args.validationSplit != null && args.validationSplit > 0 &&\n                        args.validationSplit < 1) {\n                        doValidation = true;\n                        splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n                        originalBatchSize = inputs[0].shape[0];\n                        valX = sliceArrays(inputs, splitAt, originalBatchSize);\n                        inputs = sliceArrays(inputs, 0, splitAt);\n                        valY = sliceArrays(targets, splitAt, originalBatchSize);\n                        targets = sliceArrays(targets, 0, splitAt);\n                        // TODO(cais): Once sampleWeights becomes available, slice it to get\n                        //   valSampleWeights.\n                        valIns = valX.concat(valY);\n                        // TODO(cais): Add useLearningPhase data properly.\n                    }\n                    else if (args.validationSteps != null) {\n                        doValidation = true;\n                        // TODO(cais): Add useLearningPhase.\n                    }\n                    _a.label = 5;\n                case 5:\n                    ins = inputs.concat(targets).concat(sampleWeights);\n                    model.checkTrainableWeightsConsistency();\n                    trainFunction = model.makeTrainFunction();\n                    outLabels = model.getDedupedMetricsNames();\n                    valFunction = void 0;\n                    callbackMetrics = void 0;\n                    if (doValidation) {\n                        model.makeTestFunction();\n                        valFunction = model.testFunction;\n                        callbackMetrics =\n                            outLabels.slice().concat(outLabels.map(function (n) { return 'val_' + n; }));\n                    }\n                    else {\n                        valFunction = null;\n                        valIns = [];\n                        callbackMetrics = outLabels.slice();\n                    }\n                    callbacks = base_callbacks_1.standardizeCallbacks(args.callbacks, args.yieldEvery);\n                    return [4 /*yield*/, fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null)];\n                case 6:\n                    out = _a.sent();\n                    return [2 /*return*/, out];\n                case 7:\n                    model.isTraining = false;\n                    // Memory clean up.\n                    disposeNewTensors(inputs, x);\n                    disposeNewTensors(targets, y);\n                    disposeNewTensors(valX, inputValX);\n                    disposeNewTensors(valY, inputValY);\n                    if (sampleWeights != null) {\n                        tfc.dispose(sampleWeights);\n                    }\n                    return [7 /*endfinally*/];\n                case 8: return [2 /*return*/];\n            }\n        });\n    });\n}\nexports.fitTensors = fitTensors;\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nfunction ensureTensorsRank2OrHigher(tensors) {\n    var outs = [];\n    if (tensors instanceof tfjs_core_1.Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (var i = 0; i < tensors.length; ++i) {\n        var tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(tfjs_backend_1.expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\nexports.ensureTensorsRank2OrHigher = ensureTensorsRank2OrHigher;\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nfunction disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    var oldTensorIds = [];\n    if (refTensors instanceof tfjs_core_1.Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(function (t) { return oldTensorIds.push(t.id); });\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (var name_1 in refTensors) {\n            var oldTensor = refTensors[name_1];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    var tensorsToDispose = [];\n    if (tensors instanceof tfjs_core_1.Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(function (t) {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (var name_2 in tensors) {\n            var tensor = tensors[name_2];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(function (t) {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\nexports.disposeNewTensors = disposeNewTensors;\n"},"sourceMaps":{"js":{"version":3,"file":"training_tensors.js","sourceRoot":"","sources":["../../src/engine/training_tensors.ts"],"names":[],"mappings":";AAAA;;;;;;;;GAQG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH;;GAEG;AAEH,2CAA6C;AAC7C,mDAA+E;AAE/E,wDAAgF;AAChF,oDAAgK;AAChK,oCAA0D;AAC1D,gCAA6D;AAC7D,kDAA0C;AAwI1C,SAAgB,cAAc,CAAC,SAAiB;IAC9C,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,SAAS,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,SAAS,CAAC,EAC5C,cAAM,OAAA,6DACF,SAAW,EADT,CACS,CAAC,CAAC;AACvB,CAAC;AALD,wCAKC;AAED;;;;;;;;;;;;GAYG;AACH,SAAgB,WAAW,CACvB,MAAuB,EAAE,KAAa,EAAE,IAAY;IACtD,IAAI,MAAM,IAAI,IAAI,EAAE;QAClB,OAAO,CAAC,IAAI,CAAC,CAAC;KACf;SAAM,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;QAChC,OAAO,MAAM,CAAC,GAAG,CAAC,UAAA,KAAK,IAAI,OAAA,kCAAmB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,GAAG,KAAK,CAAC,EAA/C,CAA+C,CAAC,CAAC;KAC7E;SAAM,EAAG,UAAU;QAClB,OAAO,kCAAmB,CAAC,MAAM,EAAE,KAAK,EAAE,IAAI,GAAG,KAAK,CAAC,CAAC;KACzD;AACH,CAAC;AATD,kCASC;AAED;;;;;;;;;;;;GAYG;AACH,SAAgB,oBAAoB,CAChC,MAAuB,EAAE,OAAiB;IAC5C,OAAO,GAAG,CAAC,IAAI,CAAC;QACd,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,OAAO,IAAI,CAAC;SACb;aAAM,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YAChC,OAAO,MAAM,CAAC,GAAG,CACb,UAAA,KAAK,IAAI,OAAC,oBAAoB,CAAC,KAAK,EAAE,OAAO,CAAY,EAAhD,CAAgD,CAAC,CAAC;SAChE;aAAM;YACL,oEAAoE;YACpE,sBAAsB;YACtB,OAAO,qBAAM,CACT,MAAM,EAAE,OAAO,CAAC,KAAK,KAAK,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,CAAC;SACpE;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AAfD,oDAeC;AAED;;;;;;;GAOG;AACH,SAAgB,WAAW,CACvB,IAAY,EAAE,SAAiB;IACjC,IAAM,MAAM,GAA4B,EAAE,CAAC;IAC3C,IAAI,UAAU,GAAG,CAAC,CAAC;IACnB,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,OAAO,UAAU,GAAG,IAAI,EAAE;QACxB,QAAQ,GAAG,UAAU,GAAG,SAAS,CAAC;QAClC,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,QAAQ,GAAG,IAAI,CAAC;SACjB;QACD,MAAM,CAAC,IAAI,CAAC,CAAC,UAAU,EAAE,QAAQ,CAAC,CAAC,CAAC;QACpC,UAAU,GAAG,QAAQ,CAAC;KACvB;IACD,OAAO,MAAM,CAAC;AAChB,CAAC;AAdD,kCAcC;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;GA0BG;AACH,SAAe,OAAO;AAClB,0EAA0E;AAC1E,kCAAkC;AAClC,KAAU,EAAE,CAA+B,EAAE,GAAa,EAC1D,SAAoB,EAAE,SAAkB,EAAE,MAAe,EAAE,OAAgB,EAC3E,SAA0B,EAAE,IAAmC,EAC/D,MAAiB,EAAE,OAAwB,EAAE,eAA0B,EACvE,YAAqB,EAAE,aAAsB,EAC7C,eAAwB;;;;;;oBAC1B,IAAI,SAAS,IAAI,IAAI,EAAE;wBACrB,SAAS,GAAG,EAAE,CAAC;qBAChB;oBACD,IAAI,MAAM,IAAI,IAAI,EAAE;wBAClB,MAAM,GAAG,CAAC,CAAC;qBACZ;oBACD,IAAI,OAAO,IAAI,IAAI,EAAE;wBACnB,OAAO,GAAG,IAAI,CAAC;qBAChB;oBACD,IAAI,YAAY,IAAI,IAAI,EAAE;wBACxB,YAAY,GAAG,CAAC,CAAC;qBAClB;oBAGG,YAAY,GAAG,KAAK,CAAC;oBACzB,IAAI,IAAI,IAAI,IAAI,IAAI,MAAM,IAAI,IAAI,EAAE;wBAClC,YAAY,GAAG,IAAI,CAAC;wBACpB,+BAA+B;qBAChC;oBACD,IAAI,eAAe,IAAI,IAAI,EAAE;wBAC3B,YAAY,GAAG,IAAI,CAAC;wBACpB,IAAI,aAAa,IAAI,IAAI,EAAE;4BACzB,MAAM,IAAI,mBAAU,CAChB,gEAAgE;gCAChE,oCAAoC,CAAC,CAAC;yBAC3C;qBACF;oBAEK,eAAe,GACjB,KAAK,CAAC,eAAe,CAAC,GAAG,EAAE,SAAS,EAAE,aAAa,EAAE,iBAAiB,CAAC,CAAC;oBAE5E,IAAI,eAAe,IAAI,IAAI,EAAE;wBAC3B,UAAU,GAAG,kBAAK,CAAC,CAAC,EAAE,eAAe,CAAC,CAAC;qBACxC;oBAED,IAAI,OAAO,IAAI,IAAI,EAAE;wBACnB,OAAO,GAAG,CAAC,CAAC;qBACb;oBAEK,KAA0B,mCAAkB,CAC9C,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,YAAY,EAAE,eAAe,EAAE,aAAa,EACxE,SAAS,EAAE,YAAY,EAAE,eAAe,CAAC,EAFtC,YAAY,kBAAA,EAAE,OAAO,aAAA,CAEkB;oBAC9C,YAAY,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;oBAC7B,KAAK,CAAC,OAAO,GAAG,OAAO,CAAC;oBACxB,qBAAM,YAAY,CAAC,YAAY,EAAE,EAAA;;oBAAjC,SAAiC,CAAC;oBAClC,KAAK,CAAC,aAAa,GAAG,KAAK,CAAC;wCAInB,KAAK;;;;wCACZ,qBAAM,YAAY,CAAC,YAAY,CAAC,KAAK,CAAC,EAAA;;oCAAtC,SAAsC,CAAC;oCACjC,SAAS,GAAmB,EAAE,CAAC;yCACjC,CAAA,aAAa,IAAI,IAAI,CAAA,EAArB,wBAAqB;oCACvB,MAAM,IAAI,4BAAmB,CACzB,4CAA4C,CAAC,CAAC;;oCAElD,IAAI,OAAO,KAAK,OAAO,EAAE;wCACvB,MAAM,IAAI,4BAAmB,CAAC,wCAAwC,CAAC,CAAC;qCACzE;yCAAM,IAAI,OAAO,EAAE;wCAClB,gBAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qCAC1B;oCAGK,sBAAoB,oBAAQ,CAAC,UAAU,CAAC,CAAC;oCAEzC,YAAU,WAAW,CAAC,eAAe,EAAE,SAAS,CAAC,CAAC;wDAC/C,UAAU;;;;;oDACX,SAAS,GAAmB,EAAE,CAAC;oDACrC,qBAAM,YAAY,CAAC,YAAY,CAAC,UAAU,EAAE,SAAS,CAAC,EAAA;;oDAAtD,SAAsD,CAAC;oDAEvD,GAAG,CAAC,IAAI,CAAC;wDACP,IAAM,UAAU,GAAG,SAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;wDAC1C,IAAM,QAAQ,GAAG,SAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;wDACxC,IAAM,QAAQ,GAAG,kCAAmB,CACf,mBAAiB,EAAE,UAAU,EAC7B,QAAQ,GAAG,UAAU,CAAa,CAAC;wDACxD,SAAS,CAAC,OAAO,CAAC,GAAG,UAAU,CAAC;wDAChC,SAAS,CAAC,MAAM,CAAC,GAAG,QAAQ,GAAG,UAAU,CAAC;wDAE1C,gEAAgE;wDAChE,sDAAsD;wDACtD,IAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAG,EAAE,QAAQ,CAAa,CAAC;wDACjE,IAAM,IAAI,GAAG,CAAC,CAAC,QAAQ,CAAC,CAAC;wDACzB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;4DACzC,IAAM,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;4DAC3B,IAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;4DACpB,SAAS,CAAC,KAAK,CAAC,GAAG,GAAG,CAAC;4DACvB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;4DACd,8CAA8C;yDAC/C;wDAED,IAAI,UAAU,KAAK,SAAO,CAAC,MAAM,GAAG,CAAC,EAAE,EAAG,cAAc;4DACtD,IAAI,YAAY,EAAE;gEAChB,IAAM,OAAO,GAAG,KAAK,CAAC,QAAQ,CAAC,IAAI,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;gEACxD,6DAA6D;gEAC7D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oEACzC,IAAM,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;oEAC3B,IAAM,GAAG,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;oEACvB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;oEACd,8CAA8C;oEAC9C,SAAS,CAAC,MAAM,GAAG,KAAK,CAAC,GAAG,GAAG,CAAC;iEACjC;6DACF;yDACF;oDACH,CAAC,CAAC,CAAC;oDAEH,qBAAM,YAAY,CAAC,UAAU,CAAC,UAAU,EAAE,SAAS,CAAC,EAAA;;oDAApD,SAAoD,CAAC;oDACrD,2BAAoB,CAAC,SAAS,CAAC,CAAC;oDAEhC,IAAI,KAAK,CAAC,aAAa,EAAE;;qDAExB;;;;;oCA7CM,UAAU,GAAG,CAAC;;;yCAAE,CAAA,UAAU,GAAG,SAAO,CAAC,MAAM,CAAA;kEAA3C,UAAU;;;;;;;oCAAmC,EAAE,UAAU,CAAA;;;oCAiDlE,mBAAiB,CAAC,OAAO,EAAE,CAAC;;;gCAE9B,sDAAsD;gCACtD,qBAAM,YAAY,CAAC,UAAU,CAAC,KAAK,EAAE,SAAS,CAAC,EAAA;;oCAD/C,sDAAsD;oCACtD,SAA+C,CAAC;oCAChD,IAAI,KAAK,CAAC,aAAa,EAAE;;qCAExB;;;;;oBAxEM,KAAK,GAAG,YAAY;;;yBAAE,CAAA,KAAK,GAAG,MAAM,CAAA;kDAApC,KAAK;;;;;;;oBAAiC,EAAE,KAAK,CAAA;;wBA0EtD,qBAAM,YAAY,CAAC,UAAU,EAAE,EAAA;;oBAA/B,SAA+B,CAAC;oBAEhC,qBAAM,KAAK,CAAC,OAAO,CAAC,QAAQ,EAAE,EAAA;;oBAA9B,SAA8B,CAAC;oBAC/B,sBAAO,KAAK,CAAC,OAAO,EAAC;;;;CACtB;AAED,SAAsB,UAAU;AAC5B,0EAA0E;AAC1E,kCAAkC;AAClC,KAAU,EAAE,CAAgD,EAC5D,CAAgD,EAChD,IAAuB;IAAvB,qBAAA,EAAA,SAAuB;;;;;;oBACzB,IAAI,KAAK,CAAC,UAAU,EAAE;wBACpB,MAAM,IAAI,KAAK,CACX,8DAA8D,CAAC,CAAC;qBACrE;oBACD,KAAK,CAAC,UAAU,GAAG,IAAI,CAAC;;;;oBAShB,SAAS,GAAG,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC;oBAC/D,cAAc,CAAC,SAAS,CAAC,CAAC;oBAIpB,cAAc,GAAG,KAAK,CAAC;oBAEzB,qBAAM,KAAK,CAAC,mBAAmB,CAC3B,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,WAAW,EAAE,cAAc,EACzD,SAAS,CAAC,EAAA;;oBAHZ,gBAAgB,GAClB,SAEgD;oBACpD,MAAM,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBAC7B,OAAO,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBAC9B,aAAa,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBAGhC,YAAY,GAAG,KAAK,CAAC;oBACrB,MAAM,SAAU,CAAC;yBACjB,CAAA,IAAI,CAAC,cAAc,IAAI,IAAI,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,GAAG,CAAC,CAAA,EAA7D,wBAA6D;oBAC/D,YAAY,GAAG,IAAI,CAAC;oBACpB,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;wBACpC,mDAAmD;wBACnD,SAAS,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC;wBACnC,SAAS,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC;qBACpC;yBAAM,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;wBAC3C,MAAM,IAAI,4BAAmB,CACzB,+DAA+D,CAAC,CAAC;qBACtE;yBAAM;wBACL,MAAM,IAAI,mBAAU,CAChB,+DAA+D;4BAC/D,4CAA4C;6BACzC,IAAI,CAAC,cAAc,iBAAc,CAAA,CAAC,CAAC;qBAC3C;oBAEK,mBAAiB,IAAI,CAAC;oBAExB,qBAAM,KAAK,CAAC,mBAAmB,CAC3B,SAAS,EAAE,SAAS,EAAE,IAAI,EAAE,6BAA6B,CACzD,IAAI,EAAwB,4BAA4B,CACxD,gBAAc,EAAE,SAAS,CAAC,EAAA;;oBAJ5B,eAAe,GACjB,SAGgE;oBACpE,IAAI,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC;oBAC1B,IAAI,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC;oBAC1B,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;;;oBAEtB,IACH,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,eAAe,GAAG,CAAC;wBACxD,IAAI,CAAC,eAAe,GAAG,CAAC,EAAE;wBAC5B,YAAY,GAAG,IAAI,CAAC;wBAEd,OAAO,GACT,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC;wBAC1D,iBAAiB,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;wBAC7C,IAAI,GAAG,WAAW,CAAC,MAAM,EAAE,OAAO,EAAE,iBAAiB,CAAa,CAAC;wBACnE,MAAM,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,OAAO,CAAa,CAAC;wBACrD,IAAI,GAAG,WAAW,CAAC,OAAO,EAAE,OAAO,EAAE,iBAAiB,CAAa,CAAC;wBACpE,OAAO,GAAG,WAAW,CAAC,OAAO,EAAE,CAAC,EAAE,OAAO,CAAa,CAAC;wBACvD,oEAAoE;wBACpE,sBAAsB;wBACtB,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;wBAE3B,kDAAkD;qBACnD;yBAAM,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;wBACvC,YAAY,GAAG,IAAI,CAAC;wBACpB,oCAAoC;qBACrC;;;oBAEK,GAAG,GAAG,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;oBAEzD,KAAK,CAAC,gCAAgC,EAAE,CAAC;oBAcnC,aAAa,GAAG,KAAK,CAAC,iBAAiB,EAAE,CAAC;oBAC1C,SAAS,GAAG,KAAK,CAAC,sBAAsB,EAAc,CAAC;oBAEzD,WAAW,SAA8B,CAAC;oBAC1C,eAAe,SAAU,CAAC;oBAC9B,IAAI,YAAY,EAAE;wBAChB,KAAK,CAAC,gBAAgB,EAAE,CAAC;wBACzB,WAAW,GAAG,KAAK,CAAC,YAAY,CAAC;wBACjC,eAAe;4BACX,SAAS,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,MAAM,GAAG,CAAC,EAAV,CAAU,CAAC,CAAC,CAAC;qBAC9D;yBAAM;wBACL,WAAW,GAAG,IAAI,CAAC;wBACnB,MAAM,GAAG,EAAE,CAAC;wBACZ,eAAe,GAAG,SAAS,CAAC,KAAK,EAAE,CAAC;qBACrC;oBAEK,SAAS,GAAG,qCAAoB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;oBAC5D,qBAAM,OAAO,CACrB,KAAK,EAAE,aAAa,EAAE,GAAG,EAAE,SAAS,EAAE,SAAS,EAAE,IAAI,CAAC,MAAM,EAC5D,IAAI,CAAC,OAAO,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,IAAI,CAAC,OAAO,EAC1D,eAAe,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,EAAE,IAAI,CAAC,EAAA;;oBAH7C,GAAG,GAAG,SAGuC;oBACnD,sBAAO,GAAG,EAAC;;oBAEX,KAAK,CAAC,UAAU,GAAG,KAAK,CAAC;oBACzB,mBAAmB;oBACnB,iBAAiB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;oBAC7B,iBAAiB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC;oBAC9B,iBAAiB,CAAC,IAAgB,EAAE,SAAS,CAAC,CAAC;oBAC/C,iBAAiB,CAAC,IAAgB,EAAE,SAAS,CAAC,CAAC;oBAC/C,IAAI,aAAa,IAAI,IAAI,EAAE;wBACzB,GAAG,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;qBAC5B;;;;;;CAGJ;AAtID,gCAsIC;AAED;;;;;GAKG;AACH,SAAgB,0BAA0B,CAAC,OAAwB;IACjE,IAAM,IAAI,GAAa,EAAE,CAAC;IAC1B,IAAI,OAAO,YAAY,kBAAM,EAAE;QAC7B,OAAO,GAAG,CAAC,OAAO,CAAC,CAAC;KACrB;IAED,4BAA4B;IAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;QACvC,IAAM,MAAM,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAI,MAAM,CAAC,IAAI,KAAK,CAAC,EAAE;YACrB,IAAI,CAAC,IAAI,CAAC,yBAAU,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC,CAAC;SAClC;aAAM,IAAI,MAAM,CAAC,IAAI,KAAK,CAAC,EAAE;YAC5B,MAAM,IAAI,KAAK,CACX,8DAA8D;gBAC9D,WAAW,CAAC,CAAC;SAClB;aAAM;YACL,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;SACnB;KACF;IACD,OAAO,IAAI,CAAC;AACd,CAAC;AApBD,gEAoBC;AAED;;;;;;;;;;GAUG;AACH,uDAAuD;AACvD,SAAgB,iBAAiB,CAC7B,OAAsD,EACtD,UAAyD;IAC3D,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,OAAO;KACR;IACD,IAAM,YAAY,GAAa,EAAE,CAAC;IAClC,IAAI,UAAU,YAAY,kBAAM,EAAE;QAChC,YAAY,CAAC,IAAI,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC;KAClC;SAAM,IAAI,KAAK,CAAC,OAAO,CAAC,UAAU,CAAC,EAAE;QACpC,UAAU,CAAC,OAAO,CAAC,UAAA,CAAC,IAAI,OAAA,YAAY,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAvB,CAAuB,CAAC,CAAC;KAClD;SAAM,IAAI,UAAU,IAAI,IAAI,EAAE;QAC7B,oDAAoD;QACpD,KAAK,IAAM,MAAI,IAAI,UAAU,EAAE;YAC7B,IAAM,SAAS,GAAG,UAAU,CAAC,MAAI,CAAC,CAAC;YACnC,YAAY,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC;SACjC;KACF;IAED,IAAM,gBAAgB,GAAa,EAAE,CAAC;IACtC,IAAI,OAAO,YAAY,kBAAM,EAAE;QAC7B,IAAI,YAAY,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;YAC3C,gBAAgB,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;SAChC;KACF;SAAM,IAAI,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;QACjC,OAAO,CAAC,OAAO,CAAC,UAAA,CAAC;YACf,IAAI,YAAY,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;gBACrC,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aAC1B;QACH,CAAC,CAAC,CAAC;KACJ;SAAM,IAAI,OAAO,IAAI,IAAI,EAAE;QAC1B,oDAAoD;QACpD,KAAK,IAAM,MAAI,IAAI,OAAO,EAAE;YAC1B,IAAM,MAAM,GAAG,OAAO,CAAC,MAAI,CAAC,CAAC;YAC7B,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;gBAC1C,gBAAgB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aAC/B;SACF;KACF;IAED,gBAAgB,CAAC,OAAO,CAAC,UAAA,CAAC;QACxB,IAAI,CAAC,CAAC,CAAC,UAAU,EAAE;YACjB,CAAC,CAAC,OAAO,EAAE,CAAC;SACb;IACH,CAAC,CAAC,CAAC;AACL,CAAC;AA7CD,8CA6CC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Scalar, Tensor, Tensor1D, tensor1d, util} from '@tensorflow/tfjs-core';\n\nimport {expandDims, gather, sliceAlongFirstAxis} from '../backend/tfjs_backend';\nimport {BaseCallback, configureCallbacks, CustomCallbackArgs, History, ModelLoggingVerbosity, standardizeCallbacks, YieldEveryOptions} from '../base_callbacks';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {disposeTensorsInLogs, UnresolvedLogs} from '../logs';\nimport {range} from '../utils/math_utils';\nimport {ClassWeight, ClassWeightMap} from './training_utils';\n\n/**\n * Interface configuration model training based on data as `tf.Tensor`s.\n */\nexport interface ModelFitArgs {\n  /**\n   * Number of samples per gradient update. If unspecified, it\n   * will default to 32.\n   */\n  batchSize?: number;\n\n  /** The number of times to iterate over the training data arrays. */\n  epochs?: number;\n\n  /**\n   * Verbosity level.\n   *\n   * Expected to be 0, 1, or 2. Default: 1.\n   *\n   * 0 - No printed message during fit() call.\n   * 1 - In Node.js (tfjs-node), prints the progress bar, together with\n   *     real-time updates of loss and metric values and training speed.\n   *     In the browser: no action. This is the default.\n   * 2 - Not implemented yet.\n   */\n  verbose?: ModelLoggingVerbosity;\n\n  /**\n   * List of callbacks to be called during training.\n   * Can have one or more of the following callbacks:\n   *   - `onTrainBegin(logs)`: called when training starts.\n   *   - `onTrainEnd(logs)`: called when training ends.\n   *   - `onEpochBegin(epoch, logs)`: called at the start of every epoch.\n   *   - `onEpochEnd(epoch, logs)`: called at the end of every epoch.\n   *   - `onBatchBegin(batch, logs)`: called at the start of every batch.\n   *   - `onBatchEnd(batch, logs)`: called at the end of every batch.\n   *   - `onYield(epoch, batch, logs)`: called every `yieldEvery` milliseconds\n   *      with the current epoch, batch and logs. The logs are the same\n   *      as in `onBatchEnd()`. Note that `onYield` can skip batches or\n   *      epochs. See also docs for `yieldEvery` below.\n   */\n  callbacks?: BaseCallback[]|CustomCallbackArgs|CustomCallbackArgs[];\n\n  /**\n   * Float between 0 and 1: fraction of the training data\n   * to be used as validation data. The model will set apart this fraction of\n   * the training data, will not train on it, and will evaluate the loss and\n   * any model metrics on this data at the end of each epoch.\n   * The validation data is selected from the last samples in the `x` and `y`\n   * data provided, before shuffling.\n   */\n  validationSplit?: number;\n\n  /**\n   * Data on which to evaluate the loss and any model\n   * metrics at the end of each epoch. The model will not be trained on this\n   * data. This could be a tuple [xVal, yVal] or a tuple [xVal, yVal,\n   * valSampleWeights]. The model will not be trained on this data.\n   * `validationData` will override `validationSplit`.\n   */\n  validationData?: [\n    Tensor|Tensor[], Tensor|Tensor[]\n  ]|[Tensor | Tensor[], Tensor|Tensor[], Tensor|Tensor[]];\n\n  /**\n   * Whether to shuffle the training data before each epoch. Has\n   * no effect when `stepsPerEpoch` is not `null`.\n   */\n  shuffle?: boolean;\n\n  /**\n   * Optional object mapping class indices (integers) to\n   * a weight (float) to apply to the model's loss for the samples from this\n   * class during training. This can be useful to tell the model to \"pay more\n   * attention\" to samples from an under-represented class.\n   *\n   * If the model has multiple outputs, a class weight can be specified for\n   * each of the outputs by setting this field an array of weight object\n   * or a object that maps model output names (e.g., `model.outputNames[0]`)\n   * to weight objects.\n   */\n  classWeight?: ClassWeight|ClassWeight[]|ClassWeightMap;\n\n  /**\n   * Optional array of the same length as x, containing\n   * weights to apply to the model's loss for each sample. In the case of\n   * temporal data, you can pass a 2D array with shape (samples,\n   * sequenceLength), to apply a different weight to every timestep of every\n   * sample. In this case you should make sure to specify\n   * sampleWeightMode=\"temporal\" in compile().\n   */\n  sampleWeight?: Tensor;\n\n  /**\n   * Epoch at which to start training (useful for resuming a previous training\n   * run).\n   */\n  initialEpoch?: number;\n\n  /**\n   * Total number of steps (batches of samples) before\n   * declaring one epoch finished and starting the next epoch. When training\n   * with Input Tensors such as TensorFlow data tensors, the default `null` is\n   * equal to the number of unique samples in your dataset divided by the\n   * batch size, or 1 if that cannot be determined.\n   */\n  stepsPerEpoch?: number;\n\n  /**\n   * Only relevant if `stepsPerEpoch` is specified. Total number of steps\n   * (batches of samples) to validate before stopping.\n   */\n  validationSteps?: number;\n\n  /**\n   * Configures the frequency of yielding the main thread to other tasks.\n   *\n   * In the browser environment, yielding the main thread can improve the\n   * responsiveness of the page during training. In the Node.js environment,\n   * it can ensure tasks queued in the event loop can be handled in a timely\n   * manner.\n   *\n   * The value can be one of the following:\n   *   - `'auto'`: The yielding happens at a certain frame rate (currently set\n   *               at 125ms). This is the default.\n   *   - `'batch'`: yield every batch.\n   *   - `'epoch'`: yield every epoch.\n   *   - any `number`: yield every `number` milliseconds.\n   *   - `'never'`: never yield. (yielding can still happen through `await\n   *      nextFrame()` calls in custom callbacks.)\n   */\n  yieldEvery?: YieldEveryOptions;\n}\n\nexport function checkBatchSize(batchSize: number) {\n  tfc.util.assert(\n      batchSize > 0 && Number.isInteger(batchSize),\n      () => `batchSize is required to be a positive integer, but got ${\n          batchSize}`);\n}\n\n/**\n * Slice an Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(\n    arrays: Tensor|Tensor[], start: number, stop: number): Tensor|Tensor[] {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {  // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n\n/**\n * Slice an Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(\n    arrays: Tensor|Tensor[], indices: Tensor1D): Tensor|Tensor[] {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(\n          array => (sliceArraysByIndices(array, indices) as Tensor));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(\n          arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(\n    size: number, batchSize: number): Array<[number, number]> {\n  const output: Array<[number, number]> = [];\n  let batchStart = 0;\n  let batchEnd: number = null;\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n  return output;\n}\n\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown.\n * @param epochs Number of times to iterate over the data.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run).\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n    // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n    // tslint:disable-next-line:no-any\n    model: any, f: (data: Tensor[]) => Scalar[], ins: Tensor[],\n    outLabels?: string[], batchSize?: number, epochs?: number, verbose?: number,\n    callbacks?: BaseCallback[], valF?: (data: Tensor[]) => Scalar[],\n    valIns?: Tensor[], shuffle?: boolean|string, callbackMetrics?: string[],\n    initialEpoch?: number, stepsPerEpoch?: number,\n    validationSteps?: number): Promise<History> {\n  if (batchSize == null) {\n    batchSize = 32;\n  }\n  if (epochs == null) {\n    epochs = 1;\n  }\n  if (shuffle == null) {\n    shuffle = true;\n  }\n  if (initialEpoch == null) {\n    initialEpoch = 0;\n  }\n\n  // TODO(cais): Change const to let below when implementing validation.\n  let doValidation = false;\n  if (valF != null && valIns != null) {\n    doValidation = true;\n    // TODO(cais): verbose message.\n  }\n  if (validationSteps != null) {\n    doValidation = true;\n    if (stepsPerEpoch == null) {\n      throw new ValueError(\n          'Can only use `validationSteps` when doing step-wise training, ' +\n          'i.e., `stepsPerEpoch` must be set.');\n    }\n  }\n\n  const numTrainSamples =\n      model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n  let indexArray: number[];\n  if (numTrainSamples != null) {\n    indexArray = range(0, numTrainSamples);\n  }\n\n  if (verbose == null) {\n    verbose = 1;\n  }\n\n  const {callbackList, history} = configureCallbacks(\n      callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch,\n      batchSize, doValidation, callbackMetrics);\n  callbackList.setModel(model);\n  model.history = history;\n  await callbackList.onTrainBegin();\n  model.stopTraining_ = false;\n  // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n  // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n    await callbackList.onEpochBegin(epoch);\n    const epochLogs: UnresolvedLogs = {};\n    if (stepsPerEpoch != null) {\n      throw new NotImplementedError(\n          'stepsPerEpoch mode is not implemented yet.');\n    } else {\n      if (shuffle === 'batch') {\n        throw new NotImplementedError('batch shuffling is not implemneted yet');\n      } else if (shuffle) {\n        util.shuffle(indexArray);\n      }\n      // Convert the potentially shuffled indices to Tensor1D, to avoid the\n      // cost of repeated creation of Array1Ds later on.\n      const epochIndexArray1D = tensor1d(indexArray);\n\n      const batches = makeBatches(numTrainSamples, batchSize);\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchLogs: UnresolvedLogs = {};\n        await callbackList.onBatchBegin(batchIndex, batchLogs);\n\n        tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = sliceAlongFirstAxis(\n                               epochIndexArray1D, batchStart,\n                               batchEnd - batchStart) as Tensor1D;\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = batchEnd - batchStart;\n\n          // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n          const insBatch = sliceArraysByIndices(ins, batchIds) as Tensor[];\n          const outs = f(insBatch);\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out);\n            // TODO(cais): Use scope() to avoid ownership.\n          }\n\n          if (batchIndex === batches.length - 1) {  // Last batch.\n            if (doValidation) {\n              const valOuts = model.testLoop(valF, valIns, batchSize);\n              // Porting Notes: In tfjs-layers, valOuts is always an Array.\n              for (let i = 0; i < outLabels.length; ++i) {\n                const label = outLabels[i];\n                const out = valOuts[i];\n                tfc.keep(out);\n                // TODO(cais): Use scope() to avoid ownership.\n                epochLogs['val_' + label] = out;\n              }\n            }\n          }\n        });\n\n        await callbackList.onBatchEnd(batchIndex, batchLogs);\n        disposeTensorsInLogs(batchLogs);\n\n        if (model.stopTraining_) {\n          break;\n        }\n        // TODO(cais): return outs as list of Tensor.\n      }\n\n      epochIndexArray1D.dispose();\n    }\n    // TODO(cais): Run validation at the end of the epoch.\n    await callbackList.onEpochEnd(epoch, epochLogs);\n    if (model.stopTraining_) {\n      break;\n    }\n  }\n  await callbackList.onTrainEnd();\n\n  await model.history.syncData();\n  return model.history;\n}\n\nexport async function fitTensors(\n    // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n    // tslint:disable-next-line:no-any\n    model: any, x: Tensor|Tensor[]|{[inputName: string]: Tensor},\n    y: Tensor|Tensor[]|{[inputName: string]: Tensor},\n    args: ModelFitArgs = {}): Promise<History> {\n  if (model.isTraining) {\n    throw new Error(\n        'Cannot start training because another fit() call is ongoing.');\n  }\n  model.isTraining = true;\n  let inputs: Tensor[];\n  let targets: Tensor[];\n  let inputValX: Tensor|Tensor[];\n  let inputValY: Tensor|Tensor[];\n  let valX: Tensor|Tensor[];\n  let valY: Tensor|Tensor[];\n  let sampleWeights: Tensor[];\n  try {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize);\n\n    // Validate user data.\n    // TODO(cais): Support sampleWeight.\n    const checkBatchAxis = false;\n    const standardizedOuts =\n        await model.standardizeUserData(\n            x, y, args.sampleWeight, args.classWeight, checkBatchAxis,\n            batchSize) as [Tensor[], Tensor[], Tensor[]];\n    inputs = standardizedOuts[0];\n    targets = standardizedOuts[1];\n    sampleWeights = standardizedOuts[2];\n\n    // Prepare validation data.\n    let doValidation = false;\n    let valIns: Tensor[];\n    if (args.validationData != null && args.validationData.length > 0) {\n      doValidation = true;\n      if (args.validationData.length === 2) {\n        // config.validationData consists of valX and valY.\n        inputValX = args.validationData[0];\n        inputValY = args.validationData[1];\n      } else if (args.validationData.length === 3) {\n        throw new NotImplementedError(\n            'validationData including sample weights is not supported yet.');\n      } else {\n        throw new ValueError(\n            `When passing validation data, it must contain 2 (valX, valY) ` +\n            `or 3 (valX, valY, valSampleWeight) items; ` +\n            `${args.validationData} is invalid.`);\n      }\n\n      const checkBatchAxis = true;\n      const valStandardized =\n          await model.standardizeUserData(\n              inputValX, inputValY, null, /** Unused sample weights. */\n              null,                       /** Unused class weights. */\n              checkBatchAxis, batchSize) as [Tensor[], Tensor[], Tensor[]];\n      valX = valStandardized[0];\n      valY = valStandardized[1];\n      valIns = valX.concat(valY);\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (\n        args.validationSplit != null && args.validationSplit > 0 &&\n        args.validationSplit < 1) {\n      doValidation = true;\n      // Porting Note: In tfjs-layers, inputs[0] is always an Tensor.\n      const splitAt =\n          Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n      const originalBatchSize = inputs[0].shape[0];\n      valX = sliceArrays(inputs, splitAt, originalBatchSize) as Tensor[];\n      inputs = sliceArrays(inputs, 0, splitAt) as Tensor[];\n      valY = sliceArrays(targets, splitAt, originalBatchSize) as Tensor[];\n      targets = sliceArrays(targets, 0, splitAt) as Tensor[];\n      // TODO(cais): Once sampleWeights becomes available, slice it to get\n      //   valSampleWeights.\n      valIns = valX.concat(valY);\n\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSteps != null) {\n      doValidation = true;\n      // TODO(cais): Add useLearningPhase.\n    }\n\n    const ins = inputs.concat(targets).concat(sampleWeights);\n\n    model.checkTrainableWeightsConsistency();\n\n    // TODO(cais): Handle use_learning_phase and learning_phase?\n\n    // Porting Note: Here we see a key deviation of tfjs-layers from\n    // Keras.\n    //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n    //  we do not construct symbolic computation graphs to embody the\n    //  training process. Instead, we define a function that performs the\n    //  training action. In PyKeras, the data (inputs and targets) are fed\n    //  through graph placeholders. In tfjs-layers, the data are fed as\n    //  function arguments. Since the function are defined below in the\n    //  scope, we don't have equivalents of PyKeras's\n    //  `_make_train_funciton`.\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames() as string[];\n\n    let valFunction: (data: Tensor[]) => Scalar[];\n    let callbackMetrics: string[];\n    if (doValidation) {\n      model.makeTestFunction();\n      valFunction = model.testFunction;\n      callbackMetrics =\n          outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      valFunction = null;\n      valIns = [];\n      callbackMetrics = outLabels.slice();\n    }\n\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const out = await fitLoop(\n        model, trainFunction, ins, outLabels, batchSize, args.epochs,\n        args.verbose, callbacks, valFunction, valIns, args.shuffle,\n        callbackMetrics, args.initialEpoch, null, null);\n    return out;\n  } finally {\n    model.isTraining = false;\n    // Memory clean up.\n    disposeNewTensors(inputs, x);\n    disposeNewTensors(targets, y);\n    disposeNewTensors(valX as Tensor[], inputValX);\n    disposeNewTensors(valY as Tensor[], inputValY);\n    if (sampleWeights != null) {\n      tfc.dispose(sampleWeights);\n    }\n  }\n  // TODO(cais): Add value to outLabels.\n}\n\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors: Tensor|Tensor[]): Tensor[] {\n  const outs: Tensor[] = [];\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n\n  // Make Tensors at least 2D.\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error(\n          'Expected tensor to be at least 1D, but received a 0D tensor ' +\n          '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n  return outs;\n}\n\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(\n    tensors: Tensor|Tensor[]|{[inputName: string]: Tensor},\n    refTensors: Tensor|Tensor[]|{[inputName: string]: Tensor}): void {\n  if (tensors == null) {\n    return;\n  }\n  const oldTensorIds: number[] = [];\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  const tensorsToDispose: Tensor[] = [];\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}\n"]}},"error":null,"hash":"362b17cd91d616b6cba763f839b1cce2","cacheData":{"env":{}}}