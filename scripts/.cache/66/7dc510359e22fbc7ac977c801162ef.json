{"id":"node_modules/@tensorflow/tfjs-layers/dist/layers/core.js","dependencies":[{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js.map","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\src\\layers\\core.ts","includedInParent":true,"mtime":499162500000},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\package.json","includedInParent":true,"mtime":1582861032163},{"name":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1581030261368},{"name":"@tensorflow/tfjs-core","loc":{"line":28,"column":26},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.esm.js"},{"name":"../activations","loc":{"line":29,"column":28},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\activations.js"},{"name":"../backend/tfjs_backend","loc":{"line":30,"column":16},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\backend\\tfjs_backend.js"},{"name":"../constraints","loc":{"line":31,"column":28},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\constraints.js"},{"name":"../engine/topology","loc":{"line":32,"column":25},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\topology.js"},{"name":"../errors","loc":{"line":33,"column":23},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\errors.js"},{"name":"../initializers","loc":{"line":34,"column":29},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\initializers.js"},{"name":"../regularizers","loc":{"line":35,"column":29},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\regularizers.js"},{"name":"../utils/generic_utils","loc":{"line":36,"column":30},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\generic_utils.js"},{"name":"../utils/math_utils","loc":{"line":37,"column":27},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\math_utils.js"},{"name":"../utils/types_utils","loc":{"line":38,"column":28},"parent":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js","resolved":"C:\\Users\\Jacob\\Documents\\jump(3)\\scripts\\node_modules\\@tensorflow\\tfjs-layers\\dist\\utils\\types_utils.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar activations_1 = require(\"../activations\");\nvar K = require(\"../backend/tfjs_backend\");\nvar constraints_1 = require(\"../constraints\");\nvar topology_1 = require(\"../engine/topology\");\nvar errors_1 = require(\"../errors\");\nvar initializers_1 = require(\"../initializers\");\nvar regularizers_1 = require(\"../regularizers\");\nvar generic_utils_1 = require(\"../utils/generic_utils\");\nvar math_utils_1 = require(\"../utils/math_utils\");\nvar types_utils_1 = require(\"../utils/types_utils\");\nvar Dropout = /** @class */ (function (_super) {\n    __extends(Dropout, _super);\n    function Dropout(args) {\n        var _this = _super.call(this, args) || this;\n        _this.rate = Math.max(Math.min(args.rate, 1), 0);\n        // So that the scalar doesn't get tidied up between executions.\n        _this.noiseShape = args.noiseShape;\n        _this.seed = args.seed;\n        _this.supportsMasking = true;\n        return _this;\n    }\n    Dropout.prototype.getNoiseShape = function (input) {\n        if (this.noiseShape == null) {\n            return this.noiseShape;\n        }\n        var inputShape = input.shape;\n        var noiseShape = [];\n        for (var i = 0; i < this.noiseShape.length; ++i) {\n            noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n        }\n        return noiseShape;\n    };\n    Dropout.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            if (0 < _this.rate && _this.rate < 1) {\n                var training = kwargs['training'] == null ? false : kwargs['training'];\n                var noiseShape_1 = _this.getNoiseShape(input);\n                var output = K.inTrainPhase(function () { return K.dropout(input, _this.rate, noiseShape_1, _this.seed); }, function () { return input; }, training);\n                return output;\n            }\n            return inputs;\n        });\n    };\n    Dropout.prototype.getConfig = function () {\n        var config = {\n            rate: this.rate,\n            noiseShape: this.noiseShape,\n            seed: this.seed,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    Dropout.prototype.dispose = function () {\n        return _super.prototype.dispose.call(this);\n    };\n    /** @nocollapse */\n    Dropout.className = 'Dropout';\n    return Dropout;\n}(topology_1.Layer));\nexports.Dropout = Dropout;\ntfjs_core_1.serialization.registerClass(Dropout);\nvar SpatialDropout1D = /** @class */ (function (_super) {\n    __extends(SpatialDropout1D, _super);\n    function SpatialDropout1D(args) {\n        var _this = _super.call(this, args) || this;\n        _this.inputSpec = [{ ndim: 3 }];\n        return _this;\n    }\n    SpatialDropout1D.prototype.getNoiseShape = function (input) {\n        var inputShape = input.shape;\n        return [inputShape[0], 1, inputShape[2]];\n    };\n    /** @nocollapse */\n    SpatialDropout1D.className = 'SpatialDropout1D';\n    return SpatialDropout1D;\n}(Dropout));\nexports.SpatialDropout1D = SpatialDropout1D;\ntfjs_core_1.serialization.registerClass(SpatialDropout1D);\nvar Dense = /** @class */ (function (_super) {\n    __extends(Dense, _super);\n    function Dense(args) {\n        var _this = _super.call(this, args) || this;\n        // Default activation: Linear (none).\n        _this.activation = null;\n        _this.useBias = true;\n        _this.kernel = null;\n        _this.bias = null;\n        _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        if (args.batchInputShape == null && args.inputShape == null &&\n            args.inputDim != null) {\n            // This logic is copied from Layer's constructor, since we can't\n            // do exactly what the Python constructor does for Dense().\n            var batchSize = null;\n            if (args.batchSize != null) {\n                batchSize = args.batchSize;\n            }\n            _this.batchInputShape = [batchSize, args.inputDim];\n        }\n        _this.units = args.units;\n        generic_utils_1.assertPositiveInteger(_this.units, 'units');\n        _this.activation = activations_1.getActivation(args.activation);\n        if (args.useBias != null) {\n            _this.useBias = args.useBias;\n        }\n        _this.kernelInitializer = initializers_1.getInitializer(args.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n        _this.biasInitializer =\n            initializers_1.getInitializer(args.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n        _this.kernelConstraint = constraints_1.getConstraint(args.kernelConstraint);\n        _this.biasConstraint = constraints_1.getConstraint(args.biasConstraint);\n        _this.kernelRegularizer = regularizers_1.getRegularizer(args.kernelRegularizer);\n        _this.biasRegularizer = regularizers_1.getRegularizer(args.biasRegularizer);\n        _this.activityRegularizer = regularizers_1.getRegularizer(args.activityRegularizer);\n        _this.supportsMasking = true;\n        _this.inputSpec = [{ minNDim: 2 }];\n        return _this;\n    }\n    Dense.prototype.build = function (inputShape) {\n        var _a;\n        inputShape = types_utils_1.getExactlyOneShape(inputShape);\n        var inputLastDim = inputShape[inputShape.length - 1];\n        if (this.kernel == null) {\n            this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n            if (this.useBias) {\n                this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n            }\n        }\n        this.inputSpec = [{ minNDim: 2, axes: (_a = {}, _a[-1] = inputLastDim, _a) }];\n        this.built = true;\n    };\n    Dense.prototype.computeOutputShape = function (inputShape) {\n        inputShape = types_utils_1.getExactlyOneShape(inputShape);\n        var outputShape = inputShape.slice();\n        outputShape[outputShape.length - 1] = this.units;\n        return outputShape;\n    };\n    Dense.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            // Dense layer accepts only a single input.\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            var fusedActivationName = generic_utils_1.mapActivationToFusedKernel(_this.activation.getClassName());\n            var output;\n            if (fusedActivationName != null) {\n                output = K.dot(input, _this.kernel.read(), fusedActivationName, _this.bias ? _this.bias.read() : null);\n            }\n            else {\n                output = K.dot(input, _this.kernel.read());\n                if (_this.bias != null) {\n                    output = K.biasAdd(output, _this.bias.read());\n                }\n                if (_this.activation != null) {\n                    output = _this.activation.apply(output);\n                }\n            }\n            return output;\n        });\n    };\n    Dense.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint)\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    Dense.className = 'Dense';\n    return Dense;\n}(topology_1.Layer));\nexports.Dense = Dense;\ntfjs_core_1.serialization.registerClass(Dense);\nvar Flatten = /** @class */ (function (_super) {\n    __extends(Flatten, _super);\n    function Flatten(args) {\n        var _this = this;\n        args = args || {};\n        _this = _super.call(this, args) || this;\n        _this.inputSpec = [{ minNDim: 3 }];\n        _this.dataFormat = args.dataFormat;\n        return _this;\n    }\n    Flatten.prototype.computeOutputShape = function (inputShape) {\n        inputShape = types_utils_1.getExactlyOneShape(inputShape);\n        for (var _i = 0, _a = inputShape.slice(1); _i < _a.length; _i++) {\n            var dim = _a[_i];\n            if (dim == null) {\n                throw new errors_1.ValueError(\"The shape of the input to \\\"Flatten\\\" is not fully defined \" +\n                    (\"(got \" + inputShape.slice(1) + \"). Make sure to pass a complete \") +\n                    \"\\\"input_shape\\\" or \\\"batch_input_shape\\\" argument to the first \" +\n                    \"layer in your model.\");\n            }\n        }\n        return [inputShape[0], math_utils_1.arrayProd(inputShape, 1)];\n    };\n    Flatten.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            if (_this.dataFormat === 'channelsFirst' && input.rank > 1) {\n                var permutation = [0];\n                for (var i = 2; i < input.rank; ++i) {\n                    permutation.push(i);\n                }\n                permutation.push(1);\n                input = input.transpose(permutation);\n            }\n            return K.batchFlatten(input);\n        });\n    };\n    Flatten.prototype.getConfig = function () {\n        var config = {};\n        if (this.dataFormat != null) {\n            config['dataFormat'] = this.dataFormat;\n        }\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    Flatten.className = 'Flatten';\n    return Flatten;\n}(topology_1.Layer));\nexports.Flatten = Flatten;\ntfjs_core_1.serialization.registerClass(Flatten);\nvar Activation = /** @class */ (function (_super) {\n    __extends(Activation, _super);\n    function Activation(args) {\n        var _this = _super.call(this, args) || this;\n        _this.supportsMasking = true;\n        _this.activation = activations_1.getActivation(args.activation);\n        return _this;\n    }\n    Activation.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            return _this.activation.apply(input);\n        });\n    };\n    Activation.prototype.getConfig = function () {\n        var config = { activation: activations_1.serializeActivation(this.activation) };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    Activation.className = 'Activation';\n    return Activation;\n}(topology_1.Layer));\nexports.Activation = Activation;\ntfjs_core_1.serialization.registerClass(Activation);\nvar RepeatVector = /** @class */ (function (_super) {\n    __extends(RepeatVector, _super);\n    function RepeatVector(args) {\n        var _this = _super.call(this, args) || this;\n        _this.n = args.n;\n        _this.inputSpec = [{ ndim: 2 }];\n        return _this;\n    }\n    RepeatVector.prototype.computeOutputShape = function (inputShape) {\n        return [inputShape[0], this.n, inputShape[1]];\n    };\n    RepeatVector.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            inputs = types_utils_1.getExactlyOneTensor(inputs);\n            return K.repeat(inputs, _this.n);\n        });\n    };\n    RepeatVector.prototype.getConfig = function () {\n        var config = {\n            n: this.n,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    RepeatVector.className = 'RepeatVector';\n    return RepeatVector;\n}(topology_1.Layer));\nexports.RepeatVector = RepeatVector;\ntfjs_core_1.serialization.registerClass(RepeatVector);\nvar Reshape = /** @class */ (function (_super) {\n    __extends(Reshape, _super);\n    function Reshape(args) {\n        var _this = _super.call(this, args) || this;\n        _this.targetShape = args.targetShape;\n        // Make sure that all unknown dimensions are represented as `null`.\n        for (var i = 0; i < _this.targetShape.length; ++i) {\n            if (_this.isUnknown(_this.targetShape[i])) {\n                _this.targetShape[i] = null;\n            }\n        }\n        return _this;\n    }\n    Reshape.prototype.isUnknown = function (dim) {\n        return dim < 0 || dim == null;\n    };\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n    Reshape.prototype.fixUnknownDimension = function (inputShape, outputShape) {\n        var errorMsg = 'Total size of new array must be unchanged.';\n        var finalShape = outputShape.slice();\n        var known = 1;\n        var unknown = null;\n        for (var i = 0; i < finalShape.length; ++i) {\n            var dim = finalShape[i];\n            if (this.isUnknown(dim)) {\n                if (unknown === null) {\n                    unknown = i;\n                }\n                else {\n                    throw new errors_1.ValueError('Can only specifiy one unknown dimension.');\n                }\n            }\n            else {\n                known *= dim;\n            }\n        }\n        var originalSize = math_utils_1.arrayProd(inputShape);\n        if (unknown !== null) {\n            if (known === 0 || originalSize % known !== 0) {\n                throw new errors_1.ValueError(errorMsg);\n            }\n            finalShape[unknown] = originalSize / known;\n        }\n        else if (originalSize !== known) {\n            throw new errors_1.ValueError(errorMsg);\n        }\n        return finalShape;\n    };\n    Reshape.prototype.computeOutputShape = function (inputShape) {\n        var anyUnknownDims = false;\n        for (var i = 0; i < inputShape.length; ++i) {\n            if (this.isUnknown(inputShape[i])) {\n                anyUnknownDims = true;\n                break;\n            }\n        }\n        if (anyUnknownDims) {\n            return inputShape.slice(0, 1).concat(this.targetShape);\n        }\n        else {\n            return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n        }\n    };\n    Reshape.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            var inputShape = input.shape;\n            var outputShape = inputShape.slice(0, 1).concat(_this.fixUnknownDimension(inputShape.slice(1), _this.targetShape));\n            return input.reshape(outputShape);\n        });\n    };\n    Reshape.prototype.getConfig = function () {\n        var config = {\n            targetShape: this.targetShape,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    Reshape.className = 'Reshape';\n    return Reshape;\n}(topology_1.Layer));\nexports.Reshape = Reshape;\ntfjs_core_1.serialization.registerClass(Reshape);\nvar Permute = /** @class */ (function (_super) {\n    __extends(Permute, _super);\n    function Permute(args) {\n        var _this = _super.call(this, args) || this;\n        if (args.dims == null) {\n            throw new Error('Required configuration field `dims` is missing during Permute ' +\n                'constructor call.');\n        }\n        if (!Array.isArray(args.dims)) {\n            throw new Error('Permute constructor requires `dims` to be an Array, but received ' +\n                (args.dims + \" instead.\"));\n        }\n        // Check the validity of the permutation indices.\n        var expectedSortedIndices = math_utils_1.range(1, args.dims.length + 1);\n        if (!tfjs_core_1.util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n            throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n                ' `dims` must contain consecutive integers starting from 1.');\n        }\n        _this.dims = args.dims;\n        _this.dimsIncludingBatch = [0].concat(_this.dims);\n        _this.inputSpec = [new topology_1.InputSpec({ ndim: _this.dims.length + 1 })];\n        return _this;\n    }\n    Permute.prototype.computeOutputShape = function (inputShape) {\n        inputShape = types_utils_1.getExactlyOneShape(inputShape);\n        var outputShape = inputShape.slice();\n        this.dims.forEach(function (dim, i) {\n            outputShape[i + 1] = inputShape[dim];\n        });\n        return outputShape;\n    };\n    Permute.prototype.call = function (inputs, kwargs) {\n        return tfjs_core_1.transpose(types_utils_1.getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    };\n    Permute.prototype.getConfig = function () {\n        var config = {\n            dims: this.dims,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    /** @nocollapse */\n    Permute.className = 'Permute';\n    return Permute;\n}(topology_1.Layer));\nexports.Permute = Permute;\ntfjs_core_1.serialization.registerClass(Permute);\nvar Masking = /** @class */ (function (_super) {\n    __extends(Masking, _super);\n    function Masking(args) {\n        var _this = _super.call(this, args == null ? {} : args) || this;\n        _this.supportsMasking = true;\n        if (args != null) {\n            _this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n        }\n        else {\n            _this.maskValue = 0;\n        }\n        return _this;\n    }\n    Masking.prototype.computeOutputShape = function (inputShape) {\n        return inputShape;\n    };\n    Masking.prototype.getConfig = function () {\n        var baseConfig = _super.prototype.getConfig.call(this);\n        var config = { maskValue: this.maskValue };\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    Masking.prototype.computeMask = function (inputs, mask) {\n        var input = types_utils_1.getExactlyOneTensor(inputs);\n        var axis = -1;\n        return tfjs_core_1.any(tfjs_core_1.notEqual(input, this.maskValue), axis);\n    };\n    Masking.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            _this.invokeCallHook(inputs, kwargs);\n            var input = types_utils_1.getExactlyOneTensor(inputs);\n            var axis = -1;\n            var keepDims = true;\n            var booleanMask = tfjs_core_1.any(tfjs_core_1.notEqual(input, _this.maskValue), axis, keepDims);\n            var output = input.mul(booleanMask.asType(input.dtype));\n            return output;\n        });\n    };\n    /** @nocollapse */\n    Masking.className = 'Masking';\n    return Masking;\n}(topology_1.Layer));\nexports.Masking = Masking;\ntfjs_core_1.serialization.registerClass(Masking);\n"},"sourceMaps":{"js":{"version":3,"file":"core.js","sourceRoot":"","sources":["../../src/layers/core.ts"],"names":[],"mappings":";AAAA;;;;;;;;GAQG;;;;;;;;;;;;;;;AAEH;;GAEG;AAEH,mDAAkG;AAElG,8CAA8F;AAC9F,2CAA6C;AAC7C,8CAAoG;AACpG,+CAA8E;AAC9E,oCAAqC;AACrC,gDAAyG;AAIzG,gDAAyG;AAEzG,wDAAyF;AACzF,kDAAqD;AACrD,oDAA6E;AAqB7E;IAA6B,2BAAK;IAOhC,iBAAY,IAAsB;QAAlC,YACE,kBAAM,IAAI,CAAC,SAMZ;QALC,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAChD,+DAA+D;QAC/D,KAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;QAClC,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,KAAI,CAAC,eAAe,GAAG,IAAI,CAAC;;IAC9B,CAAC;IAES,+BAAa,GAAvB,UAAwB,KAAa;QACnC,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,OAAO,IAAI,CAAC,UAAU,CAAC;SACxB;QACD,IAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;QAC/B,IAAM,UAAU,GAAU,EAAE,CAAC;QAC7B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC/C,UAAU,CAAC,IAAI,CACX,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;SACtE;QACD,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,sBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAeC;QAdC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,CAAC,GAAG,KAAI,CAAC,IAAI,IAAI,KAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,IAAM,QAAQ,GACV,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;gBAC5D,IAAM,YAAU,GAAG,KAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;gBAC7C,IAAM,MAAM,GAAG,CAAC,CAAC,YAAY,CACzB,cAAM,OAAA,CAAC,CAAC,OAAO,CAAC,KAAK,EAAE,KAAI,CAAC,IAAI,EAAE,YAAU,EAAE,KAAI,CAAC,IAAI,CAAC,EAAlD,CAAkD,EACxD,cAAM,OAAA,KAAK,EAAL,CAAK,EAAE,QAAQ,CAAC,CAAC;gBAC3B,OAAO,MAAM,CAAC;aACf;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,2BAAS,GAAT;QACE,IAAM,MAAM,GAAG;YACb,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,UAAU,EAAE,IAAI,CAAC,UAAU;YAC3B,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;QACF,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,yBAAO,GAAP;QACE,OAAO,iBAAM,OAAO,WAAE,CAAC;IACzB,CAAC;IA1DD,kBAAkB;IACX,iBAAS,GAAG,SAAS,CAAC;IA0D/B,cAAC;CAAA,AA5DD,CAA6B,gBAAK,GA4DjC;AA5DY,0BAAO;AA6DpB,yBAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AA4DrC;IAAsC,oCAAO;IAI3C,0BAAY,IAAiC;QAA7C,YACE,kBAAM,IAAI,CAAC,SAEZ;QADC,KAAI,CAAC,SAAS,GAAG,CAAC,EAAC,IAAI,EAAE,CAAC,EAAC,CAAC,CAAC;;IAC/B,CAAC;IAES,wCAAa,GAAvB,UAAwB,KAAa;QACnC,IAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;QAC/B,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC;IAXD,kBAAkB;IACX,0BAAS,GAAG,kBAAkB,CAAC;IAWxC,uBAAC;CAAA,AAbD,CAAsC,OAAO,GAa5C;AAbY,4CAAgB;AAc7B,yBAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;AAE9C;IAA2B,yBAAK;IAmB9B,eAAY,IAAoB;QAAhC,YACE,kBAAM,IAAI,CAAC,SA8BZ;QA9CD,qCAAqC;QAC7B,gBAAU,GAAiB,IAAI,CAAC;QAChC,aAAO,GAAG,IAAI,CAAC;QAGf,YAAM,GAAkB,IAAI,CAAC;QAC7B,UAAI,GAAkB,IAAI,CAAC;QAE1B,gCAA0B,GAA0B,cAAc,CAAC;QACnE,8BAAwB,GAA0B,OAAO,CAAC;QAQjE,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI;YACvD,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,gEAAgE;YAChE,2DAA2D;YAC3D,IAAI,SAAS,GAAW,IAAI,CAAC;YAC7B,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;aAC5B;YACD,KAAI,CAAC,eAAe,GAAG,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC;SACnD;QAED,KAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACxB,qCAAqB,CAAC,KAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC3C,KAAI,CAAC,UAAU,GAAG,2BAAa,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QACjD,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,KAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;SAC7B;QACD,KAAI,CAAC,iBAAiB,GAAG,6BAAc,CACnC,IAAI,CAAC,iBAAiB,IAAI,KAAI,CAAC,0BAA0B,CAAC,CAAC;QAC/D,KAAI,CAAC,eAAe;YAChB,6BAAc,CAAC,IAAI,CAAC,eAAe,IAAI,KAAI,CAAC,wBAAwB,CAAC,CAAC;QAC1E,KAAI,CAAC,gBAAgB,GAAG,2BAAa,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC7D,KAAI,CAAC,cAAc,GAAG,2BAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACzD,KAAI,CAAC,iBAAiB,GAAG,6BAAc,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChE,KAAI,CAAC,eAAe,GAAG,6BAAc,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC5D,KAAI,CAAC,mBAAmB,GAAG,6BAAc,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACpE,KAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAE5B,KAAI,CAAC,SAAS,GAAG,CAAC,EAAC,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;;IAClC,CAAC;IAEM,qBAAK,GAAZ,UAAa,UAAyB;;QACpC,UAAU,GAAG,gCAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,IAAM,YAAY,GAAG,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACvD,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;YACvB,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,CAAC,YAAY,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EAClE,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;YACzD,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EAChD,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;aACtD;SACF;QAED,IAAI,CAAC,SAAS,GAAG,CAAC,EAAC,OAAO,EAAE,CAAC,EAAE,IAAI,YAAG,GAAC,CAAC,CAAC,IAAG,YAAY,KAAC,EAAC,CAAC,CAAC;QAC5D,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,kCAAkB,GAAlB,UAAmB,UAAyB;QAC1C,UAAU,GAAG,gCAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,IAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;QACvC,WAAW,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC;QACjD,OAAO,WAAW,CAAC;IACrB,CAAC;IAED,oBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAyBC;QAxBC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,2CAA2C;YAC3C,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,IAAM,mBAAmB,GACrB,0CAA0B,CAAC,KAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC,CAAC;YAC/D,IAAI,MAAc,CAAC;YAEnB,IAAI,mBAAmB,IAAI,IAAI,EAAE;gBAC/B,MAAM,GAAG,CAAC,CAAC,GAAG,CACV,KAAK,EAAE,KAAI,CAAC,MAAM,CAAC,IAAI,EAAE,EAAE,mBAAmB,EAC9C,KAAI,CAAC,IAAI,CAAC,CAAC,CAAC,KAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;aAC1C;iBAAM;gBACL,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,KAAK,EAAE,KAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;gBAC1C,IAAI,KAAI,CAAC,IAAI,IAAI,IAAI,EAAE;oBACrB,MAAM,GAAG,CAAC,CAAC,OAAO,CAAC,MAAM,EAAE,KAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;iBAC9C;gBACD,IAAI,KAAI,CAAC,UAAU,IAAI,IAAI,EAAE;oBAC3B,MAAM,GAAG,KAAI,CAAC,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;iBACxC;aACF;YAED,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,yBAAS,GAAT;QACE,IAAM,MAAM,GAA6B;YACvC,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,UAAU,EAAE,iCAAmB,CAAC,IAAI,CAAC,UAAU,CAAC;YAChD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,iBAAiB,EAAE,mCAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,eAAe,EAAE,mCAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,iBAAiB,EAAE,mCAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,eAAe,EAAE,mCAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,mBAAmB,EAAE,mCAAoB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,gBAAgB,EAAE,iCAAmB,CAAC,IAAI,CAAC,gBAAgB,CAAC;YAC5D,cAAc,EAAE,iCAAmB,CAAC,IAAI,CAAC,cAAc,CAAC;SACzD,CAAC;QACF,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAvHD,kBAAkB;IACX,eAAS,GAAG,OAAO,CAAC;IAuH7B,YAAC;CAAA,AAzHD,CAA2B,gBAAK,GAyH/B;AAzHY,sBAAK;AA0HlB,yBAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AAOnC;IAA6B,2BAAK;IAKhC,iBAAY,IAAuB;QAAnC,iBAKC;QAJC,IAAI,GAAG,IAAI,IAAI,EAAE,CAAC;QAClB,QAAA,kBAAM,IAAI,CAAC,SAAC;QACZ,KAAI,CAAC,SAAS,GAAG,CAAC,EAAC,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChC,KAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;;IACpC,CAAC;IAED,oCAAkB,GAAlB,UAAmB,UAAyB;QAC1C,UAAU,GAAG,gCAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,KAAkB,UAAmB,EAAnB,KAAA,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,EAAnB,cAAmB,EAAnB,IAAmB,EAAE;YAAlC,IAAM,GAAG,SAAA;YACZ,IAAI,GAAG,IAAI,IAAI,EAAE;gBACf,MAAM,IAAI,mBAAU,CAChB,6DAA2D;qBAC3D,UAAQ,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,qCAAkC,CAAA;oBAC7D,iEAA6D;oBAC7D,sBAAsB,CAAC,CAAC;aAC7B;SACF;QACD,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,sBAAS,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IACnD,CAAC;IAED,sBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAgBC;QAfC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YAEpC,IAAI,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YACxC,IAAI,KAAI,CAAC,UAAU,KAAK,eAAe,IAAI,KAAK,CAAC,IAAI,GAAG,CAAC,EAAE;gBACzD,IAAM,WAAW,GAAa,CAAC,CAAC,CAAC,CAAC;gBAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;oBACnC,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBACrB;gBACD,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;gBACpB,KAAK,GAAG,KAAK,CAAC,SAAS,CAAC,WAAW,CAAC,CAAC;aACtC;YAED,OAAO,CAAC,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;QAC/B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,2BAAS,GAAT;QACE,IAAM,MAAM,GAA6B,EAAE,CAAC;QAC5C,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,MAAM,CAAC,YAAY,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC;SACxC;QACD,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAjDD,kBAAkB;IACX,iBAAS,GAAG,SAAS,CAAC;IAiD/B,cAAC;CAAA,AArDD,CAA6B,gBAAK,GAqDjC;AArDY,0BAAO;AAsDpB,yBAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AASrC;IAAgC,8BAAK;IAKnC,oBAAY,IAAyB;QAArC,YACE,kBAAM,IAAI,CAAC,SAGZ;QAFC,KAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,KAAI,CAAC,UAAU,GAAG,2BAAa,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;;IACnD,CAAC;IAED,yBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAMC;QALC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,OAAO,KAAI,CAAC,UAAU,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QACtC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,8BAAS,GAAT;QACE,IAAM,MAAM,GAAG,EAAC,UAAU,EAAE,iCAAmB,CAAC,IAAI,CAAC,UAAU,CAAC,EAAC,CAAC;QAClE,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAvBD,kBAAkB;IACX,oBAAS,GAAG,YAAY,CAAC;IAuBlC,iBAAC;CAAA,AAzBD,CAAgC,gBAAK,GAyBpC;AAzBY,gCAAU;AA0BvB,yBAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;AAcxC;IAAkC,gCAAK;IAKrC,sBAAY,IAA2B;QAAvC,YACE,kBAAM,IAAI,CAAC,SAGZ;QAFC,KAAI,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC;QAChB,KAAI,CAAC,SAAS,GAAG,CAAC,EAAC,IAAI,EAAE,CAAC,EAAC,CAAC,CAAC;;IAC/B,CAAC;IAED,yCAAkB,GAAlB,UAAmB,UAAiB;QAClC,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC;IAED,2BAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAKC;QAJC,OAAO,gBAAI,CAAC;YACV,MAAM,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,CAAC,MAAM,CAAC,MAAM,EAAE,KAAI,CAAC,CAAC,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,gCAAS,GAAT;QACE,IAAM,MAAM,GAAG;YACb,CAAC,EAAE,IAAI,CAAC,CAAC;SACV,CAAC;QACF,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IA5BD,kBAAkB;IACX,sBAAS,GAAG,cAAc,CAAC;IA4BpC,mBAAC;CAAA,AA9BD,CAAkC,gBAAK,GA8BtC;AA9BY,oCAAY;AA+BzB,yBAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C;IAA6B,2BAAK;IAKhC,iBAAY,IAAsB;QAAlC,YACE,kBAAM,IAAI,CAAC,SASZ;QARC,KAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,CAAC;QAEpC,mEAAmE;QACnE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAI,CAAC,WAAW,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAChD,IAAI,KAAI,CAAC,SAAS,CAAC,KAAI,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,EAAE;gBACvC,KAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;aAC5B;SACF;;IACH,CAAC;IAEO,2BAAS,GAAjB,UAAkB,GAAW;QAC3B,OAAO,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,IAAI,CAAC;IAChC,CAAC;IAED;;;;;;;;;;;;;OAaG;IACK,qCAAmB,GAA3B,UAA4B,UAAiB,EAAE,WAAkB;QAC/D,IAAM,QAAQ,GAAG,4CAA4C,CAAC;QAC9D,IAAM,UAAU,GAAG,WAAW,CAAC,KAAK,EAAE,CAAC;QACvC,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,IAAI,OAAO,GAAG,IAAI,CAAC;QACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC1C,IAAM,GAAG,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAC1B,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,EAAE;gBACvB,IAAI,OAAO,KAAK,IAAI,EAAE;oBACpB,OAAO,GAAG,CAAC,CAAC;iBACb;qBAAM;oBACL,MAAM,IAAI,mBAAU,CAAC,0CAA0C,CAAC,CAAC;iBAClE;aACF;iBAAM;gBACL,KAAK,IAAI,GAAG,CAAC;aACd;SACF;QAED,IAAM,YAAY,GAAG,sBAAS,CAAC,UAAU,CAAC,CAAC;QAC3C,IAAI,OAAO,KAAK,IAAI,EAAE;YACpB,IAAI,KAAK,KAAK,CAAC,IAAI,YAAY,GAAG,KAAK,KAAK,CAAC,EAAE;gBAC7C,MAAM,IAAI,mBAAU,CAAC,QAAQ,CAAC,CAAC;aAChC;YACD,UAAU,CAAC,OAAO,CAAC,GAAG,YAAY,GAAG,KAAK,CAAC;SAC5C;aAAM,IAAI,YAAY,KAAK,KAAK,EAAE;YACjC,MAAM,IAAI,mBAAU,CAAC,QAAQ,CAAC,CAAC;SAChC;QAED,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,oCAAkB,GAAlB,UAAmB,UAAiB;QAClC,IAAI,cAAc,GAAG,KAAK,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC1C,IAAI,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,EAAE;gBACjC,cAAc,GAAG,IAAI,CAAC;gBACtB,MAAM;aACP;SACF;QAED,IAAI,cAAc,EAAE;YAClB,OAAO,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;SACxD;aAAM;YACL,OAAO,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAChC,IAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;SACtE;IACH,CAAC;IAED,sBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBASC;QARC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,IAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;YAC/B,IAAM,WAAW,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAC7C,KAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAI,CAAC,WAAW,CAAC,CAAC,CAAC;YACrE,OAAO,KAAK,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,2BAAS,GAAT;QACE,IAAM,MAAM,GAAG;YACb,WAAW,EAAE,IAAI,CAAC,WAAW;SAC9B,CAAC;QACF,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IApGD,kBAAkB;IACX,iBAAS,GAAG,SAAS,CAAC;IAoG/B,cAAC;CAAA,AAtGD,CAA6B,gBAAK,GAsGjC;AAtGY,0BAAO;AAuGpB,yBAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AAYrC;IAA6B,2BAAK;IAMhC,iBAAY,IAAsB;QAAlC,YACE,kBAAM,IAAI,CAAC,SAuBZ;QAtBC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,KAAK,CACX,gEAAgE;gBAChE,mBAAmB,CAAC,CAAC;SAC1B;QACD,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YAC7B,MAAM,IAAI,KAAK,CACX,mEAAmE;iBAChE,IAAI,CAAC,IAAI,cAAW,CAAA,CAAC,CAAC;SAC9B;QAED,iDAAiD;QACjD,IAAM,qBAAqB,GAAG,kBAAK,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAC7D,IAAI,CAAC,gBAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,IAAI,EAAE,EAAE,qBAAqB,CAAC,EAAE;YACtE,MAAM,IAAI,KAAK,CACX,8BAA8B,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC;gBAC1D,4DAA4D,CAAC,CAAC;SACnE;QAED,KAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,KAAI,CAAC,kBAAkB,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,KAAI,CAAC,IAAI,CAAC,CAAC;QAChD,KAAI,CAAC,SAAS,GAAG,CAAC,IAAI,oBAAS,CAAC,EAAC,IAAI,EAAE,KAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,EAAC,CAAC,CAAC,CAAC;;IACjE,CAAC;IAED,oCAAkB,GAAlB,UAAmB,UAAyB;QAC1C,UAAU,GAAG,gCAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,IAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;QACvC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,UAAC,GAAW,EAAE,CAAS;YACvC,WAAW,CAAC,CAAC,GAAG,CAAC,CAAC,GAAI,UAAoB,CAAC,GAAG,CAAC,CAAC;QAClD,CAAC,CAAC,CAAC;QACH,OAAO,WAAW,CAAC;IACrB,CAAC;IAED,sBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAC1C,OAAO,qBAAS,CAAC,iCAAmB,CAAC,MAAM,CAAC,EAAE,IAAI,CAAC,kBAAkB,CAAC,CAAC;IACzE,CAAC;IAED,2BAAS,GAAT;QACE,IAAM,MAAM,GAAG;YACb,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;QACF,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAnDD,kBAAkB;IACX,iBAAS,GAAG,SAAS,CAAC;IAmD/B,cAAC;CAAA,AArDD,CAA6B,gBAAK,GAqDjC;AArDY,0BAAO;AAsDpB,yBAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AASrC;IAA6B,2BAAK;IAKhC,iBAAY,IAAkB;QAA9B,YACE,kBAAM,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,SAOhC;QANC,KAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,KAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC;SAC9D;aAAM;YACL,KAAI,CAAC,SAAS,GAAG,CAAC,CAAC;SACpB;;IACH,CAAC;IAED,oCAAkB,GAAlB,UAAmB,UAAyB;QAC1C,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,2BAAS,GAAT;QACE,IAAM,UAAU,GAAG,iBAAM,SAAS,WAAE,CAAC;QACrC,IAAM,MAAM,GAAG,EAAC,SAAS,EAAE,IAAI,CAAC,SAAS,EAAC,CAAC;QAC3C,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,6BAAW,GAAX,UAAY,MAAuB,EAAE,IAAsB;QACzD,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;QAC1C,IAAM,IAAI,GAAG,CAAC,CAAC,CAAC;QAChB,OAAO,eAAG,CAAC,oBAAQ,CAAC,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,CAAC,CAAC;IACpD,CAAC;IAED,sBAAI,GAAJ,UAAK,MAAuB,EAAE,MAAc;QAA5C,iBAUC;QATC,OAAO,gBAAI,CAAC;YACV,KAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,IAAM,KAAK,GAAG,iCAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,IAAM,IAAI,GAAG,CAAC,CAAC,CAAC;YAChB,IAAM,QAAQ,GAAG,IAAI,CAAC;YACtB,IAAM,WAAW,GAAG,eAAG,CAAC,oBAAQ,CAAC,KAAK,EAAE,KAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;YACzE,IAAM,MAAM,GAAG,KAAK,CAAC,GAAG,CAAC,WAAW,CAAC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;YAC1D,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAzCD,kBAAkB;IACX,iBAAS,GAAG,SAAS,CAAC;IAyC/B,cAAC;CAAA,AA3CD,CAA6B,gBAAK,GA2CjC;AA3CY,0BAAO;AA4CpB,yBAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\n\nimport {any, notEqual, serialization, Tensor, tidy, transpose, util} from '@tensorflow/tfjs-core';\n\nimport {Activation as ActivationFn, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {DisposeResult, InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {LayerConfig} from '../keras_format/topology_config';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {assertPositiveInteger, mapActivationToFusedKernel} from '../utils/generic_utils';\nimport {arrayProd, range} from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface DropoutLayerArgs extends LayerArgs {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /**\n   * Integer array representing the shape of the binary dropout mask that will\n   * be multiplied with the input.\n   *\n   * For instance, if your inputs have shape `(batchSize, timesteps, features)`\n   * and you want the dropout mask to be the same for all timesteps, you can use\n   * `noise_shape=(batch_size, 1, features)`.\n   */\n  noiseShape?: number[];\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class Dropout extends Layer {\n  /** @nocollapse */\n  static className = 'Dropout';\n  private readonly rate: number;\n  private readonly noiseShape: number[];\n  private readonly seed: number;\n\n  constructor(args: DropoutLayerArgs) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n    const inputShape = input.shape;\n    const noiseShape: Shape = [];\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(\n          this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n    return noiseShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (0 < this.rate && this.rate < 1) {\n        const training =\n            kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(\n            () => K.dropout(input, this.rate, noiseShape, this.seed),\n            () => input, training);\n        return output;\n      }\n      return inputs;\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  dispose(): DisposeResult {\n    return super.dispose();\n  }\n}\nserialization.registerClass(Dropout);\n\nexport declare interface DenseLayerArgs extends LayerArgs {\n  /** Positive integer, dimensionality of the output space. */\n  units: number;\n  /**\n   * Activation function to use.\n   *\n   * If unspecified, no activation is applied.\n   */\n  activation?: ActivationIdentifier;\n  /** Whether to apply a bias. */\n  useBias?: boolean;\n  /**\n   * Initializer for the dense kernel weights matrix.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * If specified, defines inputShape as `[inputDim]`.\n   */\n  inputDim?: number;\n\n  /**\n   * Constraint for the kernel weights.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function applied to the dense kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport interface SpatialDropout1DLayerConfig extends LayerConfig {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class SpatialDropout1D extends Dropout {\n  /** @nocollapse */\n  static className = 'SpatialDropout1D';\n\n  constructor(args: SpatialDropout1DLayerConfig) {\n    super(args);\n    this.inputSpec = [{ndim: 3}];\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n}\nserialization.registerClass(SpatialDropout1D);\n\nexport class Dense extends Layer {\n  /** @nocollapse */\n  static className = 'Dense';\n  private units: number;\n  // Default activation: Linear (none).\n  private activation: ActivationFn = null;\n  private useBias = true;\n  private kernelInitializer: Initializer;\n  private biasInitializer: Initializer;\n  private kernel: LayerVariable = null;\n  private bias: LayerVariable = null;\n\n  readonly DEFAULT_KERNEL_INITIALIZER: InitializerIdentifier = 'glorotNormal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n  private readonly kernelConstraint?: Constraint;\n  private readonly biasConstraint?: Constraint;\n  private readonly kernelRegularizer?: Regularizer;\n  private readonly biasRegularizer?: Regularizer;\n\n  constructor(args: DenseLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null &&\n        args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n\n    this.inputSpec = [{minNDim: 2}];\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n    if (this.kernel == null) {\n      this.kernel = this.addWeight(\n          'kernel', [inputLastDim, this.units], null, this.kernelInitializer,\n          this.kernelRegularizer, true, this.kernelConstraint);\n      if (this.useBias) {\n        this.bias = this.addWeight(\n            'bias', [this.units], null, this.biasInitializer,\n            this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{minNDim: 2, axes: {[-1]: inputLastDim}}];\n    this.built = true;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Dense layer accepts only a single input.\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName =\n          mapActivationToFusedKernel(this.activation.getClassName());\n      let output: Tensor;\n\n      if (fusedActivationName != null) {\n        output = K.dot(\n            input, this.kernel.read(), fusedActivationName,\n            this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dense);\n\nexport declare interface FlattenLayerArgs extends LayerArgs {\n  /** Image data format: channeLast (default) or channelFirst. */\n  dataFormat?: DataFormat;\n}\n\nexport class Flatten extends Layer {\n  private dataFormat: DataFormat;\n\n  /** @nocollapse */\n  static className = 'Flatten';\n  constructor(args?: FlattenLayerArgs) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{minNDim: 3}];\n    this.dataFormat = args.dataFormat;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(\n            `The shape of the input to \"Flatten\" is not fully defined ` +\n            `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n            `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n            `layer in your model.`);\n      }\n    }\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n\n      let input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation: number[] = [0];\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n        permutation.push(1);\n        input = input.transpose(permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {};\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Flatten);\n\nexport declare interface ActivationLayerArgs extends LayerArgs {\n  /**\n   * Name of the activation function to use.\n   */\n  activation: ActivationIdentifier;\n}\n\nexport class Activation extends Layer {\n  /** @nocollapse */\n  static className = 'Activation';\n  activation: ActivationFn;\n\n  constructor(args: ActivationLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {activation: serializeActivation(this.activation)};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Activation);\n\nexport declare interface ReshapeLayerArgs extends LayerArgs {\n  /** The target shape. Does not include the batch axis. */\n  targetShape: Shape;\n}\n\nexport declare interface RepeatVectorLayerArgs extends LayerArgs {\n  /**\n   * The integer number of times to repeat the input.\n   */\n  n: number;\n}\n\nexport class RepeatVector extends Layer {\n  /** @nocollapse */\n  static className = 'RepeatVector';\n  readonly n: number;\n\n  constructor(args: RepeatVectorLayerArgs) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{ndim: 2}];\n  }\n\n  computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      n: this.n,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(RepeatVector);\n\nexport class Reshape extends Layer {\n  /** @nocollapse */\n  static className = 'Reshape';\n  private targetShape: Shape;\n\n  constructor(args: ReshapeLayerArgs) {\n    super(args);\n    this.targetShape = args.targetShape;\n\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  private isUnknown(dim: number): boolean {\n    return dim < 0 || dim == null;\n  }\n\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n  private fixUnknownDimension(inputShape: Shape, outputShape: Shape): Shape {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  computeOutputShape(inputShape: Shape): Shape {\n    let anyUnknownDims = false;\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return input.reshape(outputShape);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      targetShape: this.targetShape,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Reshape);\n\nexport declare interface PermuteLayerArgs extends LayerArgs {\n  /**\n   * Array of integers. Permutation pattern. Does not include the\n   * sample (batch) dimension. Index starts at 1.\n   * For instance, `[2, 1]` permutes the first and second dimensions\n   * of the input.\n   */\n  dims: number[];\n}\n\nexport class Permute extends Layer {\n  /** @nocollapse */\n  static className = 'Permute';\n  readonly dims: number[];\n  private readonly dimsIncludingBatch: number[];\n\n  constructor(args: PermuteLayerArgs) {\n    super(args);\n    if (args.dims == null) {\n      throw new Error(\n          'Required configuration field `dims` is missing during Permute ' +\n          'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error(\n          'Permute constructor requires `dims` to be an Array, but received ' +\n          `${args.dims} instead.`);\n    }\n\n    // Check the validity of the permutation indices.\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error(\n          'Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n          ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({ndim: this.dims.length + 1})];\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim: number, i: number) => {\n      outputShape[i + 1] = (inputShape as Shape)[dim];\n    });\n    return outputShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      dims: this.dims,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Permute);\n\nexport declare interface MaskingArgs extends LayerArgs {\n  /**\n   * Masking Value. Defaults to `0.0`.\n   */\n  maskValue?: number;\n}\n\nexport class Masking extends Layer {\n  /** @nocollapse */\n  static className = 'Masking';\n  maskValue: number;\n\n  constructor(args?: MaskingArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {maskValue: this.maskValue};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = input.mul(booleanMask.asType(input.dtype));\n      return output;\n    });\n  }\n}\nserialization.registerClass(Masking);\n"]}},"error":null,"hash":"f5fb8f8e7cb9cc7c9f1f0eb23f661b25","cacheData":{"env":{}}}